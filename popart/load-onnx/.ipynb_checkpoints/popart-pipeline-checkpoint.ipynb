{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import popart\n",
    "import numpy as np\n",
    "from typing import *\n",
    "import time\n",
    "import onnx\n",
    "from itertools import chain\n",
    "from onnx.helper import make_attribute, make_node\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_an_anchor(onnx_model_builder: popart.Builder, anchor_return_type: str = \"ALL\"):\n",
    "    return {output_name: popart.AnchorReturnType(anchor_return_type) \n",
    "                for output_name in onnx_model_builder.getOutputTensorIds()}\n",
    "\n",
    "def set_batch_size(shape: List, batch_size = 1):\n",
    "    \"\"\" shape is like [unknow_batch_size, n1, n2, ...] \"\"\"\n",
    "    shape[0] = batch_size if shape[0] == 0 else shape[0]\n",
    "    return shape\n",
    "\n",
    "def convert_popart_dtype(dtype: str):\n",
    "    dtype_conv_dic = {\n",
    "        \"int64\": \"INT32\",\n",
    "        \"int32\": \"INT32\",\n",
    "        \"float32\": \"FLOAT\",\n",
    "        \"float16\": \"FLOAT16\",\n",
    "        \"float64\": \"FLOAT\",\n",
    "    }\n",
    "\n",
    "    return dtype_conv_dic[dtype]\n",
    "\n",
    "def convert_numpy_dtype(dtype: str):\n",
    "    dtype_conv_dic = {\n",
    "        \"int64\": np.int32, \n",
    "        \"int32\": np.int32, \n",
    "        \"float32\": np.float32,\n",
    "        \"float\": np.float32,\n",
    "        \"float64\": np.float32,\n",
    "    }\n",
    "    return dtype_conv_dic[dtype.lower()]\n",
    "\n",
    "\n",
    "def add_shapeinfo_from_onnx(onnx_model_builder: popart.Builder, batch_size = 1, batch_per_step = 1):\n",
    "    inputs_tensor_id = onnx_model_builder.getInputTensorIds()\n",
    "    outputs_tensor_id = onnx_model_builder.getOutputTensorIds()\n",
    "\n",
    "    print(inputs_tensor_id)\n",
    "    inputs_shapes = [set_batch_size(onnx_model_builder.getTensorShape(i), \n",
    "                                batch_size=batch_size * batch_per_step) for i in inputs_tensor_id]\n",
    "    print(inputs_shapes)\n",
    "    inputs_dtypes = [convert_popart_dtype(onnx_model_builder.getTensorDtypeString(i)) for i in inputs_tensor_id]\n",
    "    print(inputs_dtypes)\n",
    "\n",
    "    inputs_tensor_shapes = [set_batch_size(onnx_model_builder.getTensorShape(i), \n",
    "                                batch_size=batch_size) for i in inputs_tensor_id + outputs_tensor_id]\n",
    "    inputs_tensor_dtypes = [convert_popart_dtype(onnx_model_builder.getTensorDtypeString(i)) for i in inputs_tensor_id + outputs_tensor_id]\n",
    "\n",
    "    inputShapeInfo = popart.InputShapeInfo()\n",
    "\n",
    "    for tid, tshape, tdype in zip(inputs_tensor_id + outputs_tensor_id, inputs_tensor_shapes, inputs_tensor_dtypes):\n",
    "        inputShapeInfo.add(tid, popart.TensorInfo(tdype, tshape))\n",
    "\n",
    "    return inputs_tensor_id, inputShapeInfo, inputs_shapes, inputs_dtypes\n",
    "\n",
    "\n",
    "def fake_dataset(inputs_tensor_id, inputs_shapes, inputs_dtypes, num_samples = 100):\n",
    "    for _ in range(num_samples):\n",
    "        yield { i: np.random.randint(12, size=s).astype(convert_numpy_dtype(d)) for i, s, d in zip(inputs_tensor_id, inputs_shapes, inputs_dtypes) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(builder, opts, batch_size = 1, batch_per_step = 1, n_sample = None):\n",
    "\n",
    "    global_batch_size = batch_per_step * batch_size\n",
    "    n_sample = n_sample or global_batch_size\n",
    "\n",
    "    # builder = popart.Builder(\"qtc35/model.onnx\")\n",
    "    # builder = popart.Builder(\"subqtc-manually.onnx\")\n",
    "    # builder = popart.Builder(\"qtc211-tf-ipu/qtcv211-int32-manual.onnx\")\n",
    "    # builder = popart.Builder(\"reproducer/sub_qtcv211.onnx\")\n",
    "    anchors = make_an_anchor(builder)\n",
    "    inputs_tensor_id, inputShapeInfo, inputs_shapes, inputs_dtypes = add_shapeinfo_from_onnx(builder, batch_size=batch_size, batch_per_step = batch_per_step)\n",
    "    # anchors = {output_name: popart.AnchorReturnType(\"All\") for output_name in builder.getOutputTensorIds() }\n",
    "    dataflow = popart.DataFlow(batch_per_step, anchors)\n",
    "    device = popart.DeviceManager().acquireAvailableDevice(2)\n",
    "    # device = popart.DeviceManager().createCpuDevice()\n",
    "\n",
    "    # opts = popart.SessionOptions()\n",
    "    # opts.virtualGraphMode = popart.VirtualGraphMode.Manual\n",
    "    # opts.enablePipelining = True\n",
    "    # partials_type = \"half\"\n",
    "    # opts.partialsTypeMatMuls = partials_type\n",
    "    # opts.convolutionOptions = {'partialsType': partials_type}\n",
    "    # opts.groupHostSync = True\n",
    "\n",
    "    # builder.virtualGraph(\"Reshape_1:0\", 0)\n",
    "    # builder.virtualGraph(\"Reshape_2:0\", 1)  \n",
    "    # builder.virtualGraph(\"Reshape:0\", 2)\n",
    "    # builder.virtualGraph(\"prob\", 3)\n",
    "    # builder.pipelineStage(\"Reshape_1:0\", 0)\n",
    "    # builder.pipelineStage(\"Reshape_2:0\", 1)\n",
    "    # builder.pipelineStage(\"Reshape:0\", 2)\n",
    "    # builder.pipelineStage(\"prob\", 3)\n",
    "\n",
    "    # session = popart.InferenceSession(builder.getModelProto(), dataflow, device, inputShapeInfo)\n",
    "    session = popart.InferenceSession(builder.getModelProto(), dataflow, device, \n",
    "                                    inputShapeInfo=inputShapeInfo,\n",
    "                                    userOptions=opts)\n",
    "\n",
    "    session.prepareDevice()\n",
    "    anchors = session.initAnchorArrays()\n",
    "\n",
    "    durations = []\n",
    "\n",
    "    for feed_dict in fake_dataset(inputs_tensor_id, inputs_shapes, inputs_dtypes, num_samples=n_sample):\n",
    "\n",
    "        print(\"[qtc-inference] Starting batch inference\")\n",
    "        stepio = popart.PyStepIO(feed_dict, anchors)\n",
    "        # start = time.perf_counter()\n",
    "        session.run(stepio)\n",
    "        for k, v in anchors.items():\n",
    "            print(v)\n",
    "        # duration = time.perf_counter() - start\n",
    "\n",
    "        # durations.append(duration / global_batch_size)\n",
    "\n",
    "    # np_dur = np.array(durations[10:]).mean()\n",
    "    # print(f\"Latency: {np_dur} s/sample(mean)\")\n",
    "\n",
    "    # for k, v in anchors.items():\n",
    "    #     print(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = popart.Builder(\"qtc35/model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = popart.SessionOptions()\n",
    "opts.virtualGraphMode = popart.VirtualGraphMode.Auto\n",
    "# opts.enablePipelining = True\n",
    "partials_type = \"half\"\n",
    "opts.partialsTypeMatMuls = partials_type\n",
    "opts.convolutionOptions = {'partialsType': partials_type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = onnx.load(\"qtc35/model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_qt_ns = [n.output for n in m.graph.node if n.name.startswith(\"reload_qt/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_ns = [n.output for n in m.graph.node if n.name.startswith(\"reload/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_ns = [n.output for n in m.graph.node if not n.name.startswith(\"reload\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipuconfig_in_attributes(node):\n",
    "    for a in node.attribute:\n",
    "        if a.name == \"__ipu_number\":\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipuconfig_in_attributes(make_node(\"Cast\", inputs=[\"a\"], outputs=[\"c\"], to = 7, __ipu_number = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__ipu_number\"\n",
       "i: 0\n",
       "type: INT"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_attribute(\"__ipu_number\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in m.graph.node:\n",
    "    if node.name.startswith(\"reload_qt/\"):\n",
    "        if not ipuconfig_in_attributes(node):\n",
    "            node.attribute.append(make_attribute(\"__ipu_number\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in m.graph.node:\n",
    "    if node.name.startswith(\"reload/\"):\n",
    "        if not ipuconfig_in_attributes(node):\n",
    "            node.attribute.append(make_attribute(\"__ipu_number\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in m.graph.node:\n",
    "    if not node.name.startswith(\"reload\"):\n",
    "        if not ipuconfig_in_attributes(node):\n",
    "            node.attribute.append(make_attribute(\"__ipu_number\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(72,\n",
       "  input: \"const_fold_opt__1614\"\n",
       "  input: \"const_fold_opt__1618\"\n",
       "  output: \"Concat__453:0\"\n",
       "  name: \"Concat__453\"\n",
       "  op_type: \"Concat\"\n",
       "  attribute {\n",
       "    name: \"axis\"\n",
       "    i: 0\n",
       "    type: INT\n",
       "  }\n",
       "  attribute {\n",
       "    name: \"__ipu_number\"\n",
       "    i: 1\n",
       "    type: INT\n",
       "  }\n",
       "  domain: \"\")]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, n) for i, n in enumerate(m.graph.node) if \"Concat__453\" in n.name ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__ipu_number\"\n",
       "i: 0\n",
       "type: INT"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.graph.node[72].attribute[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'attribute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3349f4f928eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHasExtension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"attribute\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'attribute'"
     ]
    }
   ],
   "source": [
    "m.graph.node[6].HasExtension(\"attribute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function RepeatedCompositeContainer.append>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.graph.node[6].attribute.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Ore in chain(*reload_ns):\n",
    "    try:\n",
    "        builder.virtualGraph(Oqt, 1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Oqt in chain(*reload_qt_ns):\n",
    "    builder.virtualGraph(Oqt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk = onnx.load_from_string(builder.getModelProto())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input: \"reload_qt/SequenceMask/Cast:0\"\n",
       "output: \"reload_qt/SequenceMask/Less__1199:0\"\n",
       "name: \"reload_qt/SequenceMask/Less__1199\"\n",
       "op_type: \"Cast\"\n",
       "attribute {\n",
       "  name: \"to\"\n",
       "  i: 1\n",
       "  type: INT\n",
       "}\n",
       "attribute {\n",
       "  name: \"__ipu_number\"\n",
       "  i: 0\n",
       "  type: INT\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk.graph.node[64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Oqt in chain(*rest_ns[1:]):\n",
    "    builder.virtualGraph(Oqt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Concat__453:0']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_ns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "popart_exception",
     "evalue": "Node already has attribute __ipu_number.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mpopart_exception\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-091a5fd61b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtualGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Concat__453:0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mpopart_exception\u001b[0m: Node already has attribute __ipu_number."
     ]
    }
   ],
   "source": [
    "builder.virtualGraph('Concat__453:0', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = popart.SessionOptions()\n",
    "opts.virtualGraphMode = popart.VirtualGraphMode.Manual\n",
    "# opts.enablePipelining = True\n",
    "partials_type = \"half\"\n",
    "opts.partialsTypeMatMuls = partials_type\n",
    "opts.convolutionOptions = {'partialsType': partials_type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorDict/StandardKvParser_4:0', 'TensorDict/StandardKvParser_1:0', 'TensorDict/StandardKvParser_6:0', 'TensorDict/StandardKvParser_8:0']\n",
      "[[1, 512], [1, 64], [1, 512], [1, 64]]\n",
      "['INT32', 'INT32', 'INT32', 'INT32']\n"
     ]
    },
    {
     "ename": "popart_exception",
     "evalue": "Either all Ops in the main graph must have their virtual graph ids set, or none must. Op count per virtual graph id\n  -1 : 790\n  0 : 790\n  1 : 42\nOps with no virtual graph id :  \n  101 (ai.onnx.Reshape:5)\n  106 (ai.onnx.Expand:8)\n  109 (ai.onnx.Reshape:5)\n  110 (ai.onnx.Gather:11)\n  115 (ai.onnx.Reshape:5)\n  120 (ai.onnx.Equal:11)\n  121 (ai.onnx.Not:1)\n  122 (ai.onnx.Cast:9)\n  123 (ai.onnx.ReduceSum:11)\n  124 (ai.onnx.Reshape:5)\n  125 (ai.onnx.Cast:9)\n  126 (ai.onnx.Cast:9)\n  127 (ai.onnx.Less:9)\n  128 (ai.onnx.Cast:9)\n  129 (ai.onnx.Reshape:5)\n  130 (ai.onnx.Mul:7)\n  131 (ai.onnx.Reshape:5)\n  132 (ai.onnx.Sub:7)\n  133 (ai.onnx.Mul:7)\n  963 (ai.onnx.OneHot:11)\n  964 (ai.onnx.MatMul:9)\n  965 (ai.onnx.Reshape:5)\n  966 (ai.onnx.Add:7)\n  967 (ai.onnx.Add:7)\n  968 (ai.onnx.ReduceMean:11)\n  969 (ai.onnx.Cast:9)\n  970 (ai.onnx.Cast:9)\n  971 (ai.onnx.Sub:7)\n  972 (ai.onnx.Mul:7)\n  973 (ai.onnx.GlobalAveragePool:1)\n  974 (ai.onnx.Cast:9)\n  975 (ai.onnx.Add:7)\n  976 (ai.onnx.Sqrt:6)\n  977 (ai.onnx.Reciprocal:6)\n  978 (ai.onnx.Mul:7)\n  979 (ai.onnx.Mul:7)\n  980 (ai.onnx.Sub:7)\n  981 (ai.onnx.Mul:7)\n  982 (ai.onnx.Add:7)\n  995 (ai.onnx.Reshape:5)\n  996 (ai.onnx.MatMul:9)\n  997 (ai.onnx.Add:7)\n  998 (ai.onnx.Reshape:5)\n  999 (ai.onnx.Transpose:1)\n  1000 (ai.onnx.MatMul:9)\n  1001 (ai.onnx.Add:7)\n  1002 (ai.onnx.Reshape:5)\n  1003 (ai.onnx.Transpose:1)\n  1004 (ai.onnx.MatMul:9)\n  1005 (ai.onnx.Add:7)\n  1006 (ai.onnx.Reshape:5)\n  1007 (ai.onnx.Transpose:1)\n  1008 (ai.onnx.MatMul:9)\n  1009 (ai.onnx.Mul:7)\n  1010 (ai.onnx.Add:7)\n  1011 (ai.onnx.Softmax:11)\n  1012 (ai.onnx.MatMul:9)\n  1013 (ai.onnx.Transpose:1)\n  1014 (ai.onnx.Reshape:5)\n  1015 (ai.onnx.MatMul:9)\n  1016 (ai.onnx.Add:7)\n  1017 (ai.onnx.Add:7)\n  1018 (ai.onnx.ReduceMean:11)\n  1019 (ai.onnx.Cast:9)\n  1020 (ai.onnx.Cast:9)\n  1021 (ai.onnx.Sub:7)\n  1022 (ai.onnx.Mul:7)\n  1023 (ai.onnx.ReduceMean:11)\n  1024 (ai.onnx.Cast:9)\n  1025 (ai.onnx.Add:7)\n  1026 (ai.onnx.Sqrt:6)\n  1027 (ai.onnx.Reciprocal:6)\n  1028 (ai.onnx.Mul:7)\n  1029 (ai.onnx.Mul:7)\n  1030 (ai.onnx.Sub:7)\n  1031 (ai.onnx.Mul:7)\n  1032 (ai.onnx.Add:7)\n  1033 (ai.onnx.MatMul:9)\n  1034 (ai.onnx.Add:7)\n  1035 (ai.onnx.Div:7)\n  1036 (ai.onnx.Erf:9)\n  1037 (ai.onnx.Add:7)\n  1038 (ai.onnx.Mul:7)\n  1039 (ai.onnx.Mul:7)\n  1040 (ai.onnx.MatMul:9)\n  1041 (ai.onnx.Add:7)\n  1042 (ai.onnx.Add:7)\n  1043 (ai.onnx.ReduceMean:11)\n  1044 (ai.onnx.Cast:9)\n  1045 (ai.onnx.Cast:9)\n  1046 (ai.onnx.Sub:7)\n  1047 (ai.onnx.Mul:7)\n  1048 (ai.onnx.ReduceMean:11)\n  1049 (ai.onnx.Cast:9)\n  1050 (ai.onnx.Add:7)\n  1051 (ai.onnx.Sqrt:6)\n  1052 (ai.onnx.Reciprocal:6)\n  1053 (ai.onnx.Mul:7)\n  1054 (ai.onnx.Mul:7)\n  1055 (ai.onnx.Sub:7)\n  1056 (ai.onnx.Mul:7)\n  1057 (ai.onnx.Add:7)\n  1058 (ai.onnx.MatMul:9)\n  1059 (ai.onnx.Add:7)\n  1060 (ai.onnx.Reshape:5)\n  1061 (ai.onnx.Transpose:1)\n  1062 (ai.onnx.MatMul:9)\n  1063 (ai.onnx.Add:7)\n  1064 (ai.onnx.Reshape:5)\n  1065 (ai.onnx.Transpose:1)\n  1066 (ai.onnx.MatMul:9)\n  1067 (ai.onnx.Add:7)\n  1068 (ai.onnx.Reshape:5)\n  1069 (ai.onnx.Transpose:1)\n  1070 (ai.onnx.MatMul:9)\n  1071 (ai.onnx.Mul:7)\n  1072 (ai.onnx.Add:7)\n  1073 (ai.onnx.Softmax:11)\n  1074 (ai.onnx.MatMul:9)\n  1075 (ai.onnx.Transpose:1)\n  1076 (ai.onnx.Reshape:5)\n  1077 (ai.onnx.MatMul:9)\n  1078 (ai.onnx.Add:7)\n  1079 (ai.onnx.Add:7)\n  1080 (ai.onnx.ReduceMean:11)\n  1081 (ai.onnx.Cast:9)\n  1082 (ai.onnx.Cast:9)\n  1083 (ai.onnx.Sub:7)\n  1084 (ai.onnx.Mul:7)\n  1085 (ai.onnx.ReduceMean:11)\n  1086 (ai.onnx.Cast:9)\n  1087 (ai.onnx.Add:7)\n  1088 (ai.onnx.Sqrt:6)\n  1089 (ai.onnx.Reciprocal:6)\n  1090 (ai.onnx.Mul:7)\n  1091 (ai.onnx.Mul:7)\n  1092 (ai.onnx.Sub:7)\n  1093 (ai.onnx.Mul:7)\n  1094 (ai.onnx.Add:7)\n  1095 (ai.onnx.MatMul:9)\n  1096 (ai.onnx.Add:7)\n  1097 (ai.onnx.Div:7)\n  1098 (ai.onnx.Erf:9)\n  1099 (ai.onnx.Add:7)\n  1100 (ai.onnx.Mul:7)\n  1101 (ai.onnx.Mul:7)\n  1102 (ai.onnx.MatMul:9)\n  1103 (ai.onnx.Add:7)\n  1104 (ai.onnx.Add:7)\n  1105 (ai.onnx.ReduceMean:11)\n  1106 (ai.onnx.Cast:9)\n  1107 (ai.onnx.Cast:9)\n  1108 (ai.onnx.Sub:7)\n  1109 (ai.onnx.Mul:7)\n  1110 (ai.onnx.ReduceMean:11)\n  1111 (ai.onnx.Cast:9)\n  1112 (ai.onnx.Add:7)\n  1113 (ai.onnx.Sqrt:6)\n  1114 (ai.onnx.Reciprocal:6)\n  1115 (ai.onnx.Mul:7)\n  1116 (ai.onnx.Mul:7)\n  1117 (ai.onnx.Sub:7)\n  1118 (ai.onnx.Mul:7)\n  1119 (ai.onnx.Add:7)\n  1120 (ai.onnx.MatMul:9)\n  1121 (ai.onnx.Add:7)\n  1122 (ai.onnx.Reshape:5)\n  1123 (ai.onnx.Transpose:1)\n  1124 (ai.onnx.MatMul:9)\n  1125 (ai.onnx.Add:7)\n  1126 (ai.onnx.Reshape:5)\n  1127 (ai.onnx.Transpose:1)\n  1128 (ai.onnx.MatMul:9)\n  1129 (ai.onnx.Add:7)\n  1130 (ai.onnx.Reshape:5)\n  1131 (ai.onnx.Transpose:1)\n  1132 (ai.onnx.MatMul:9)\n  1133 (ai.onnx.Mul:7)\n  1134 (ai.onnx.Add:7)\n  1135 (ai.onnx.Softmax:11)\n  1136 (ai.onnx.MatMul:9)\n  1137 (ai.onnx.Transpose:1)\n  1138 (ai.onnx.Reshape:5)\n  1139 (ai.onnx.MatMul:9)\n  1140 (ai.onnx.Add:7)\n  1141 (ai.onnx.Add:7)\n  1142 (ai.onnx.ReduceMean:11)\n  1143 (ai.onnx.Cast:9)\n  1144 (ai.onnx.Cast:9)\n  1145 (ai.onnx.Sub:7)\n  1146 (ai.onnx.Mul:7)\n  1147 (ai.onnx.ReduceMean:11)\n  1148 (ai.onnx.Cast:9)\n  1149 (ai.onnx.Add:7)\n  1150 (ai.onnx.Sqrt:6)\n  1151 (ai.onnx.Reciprocal:6)\n  1152 (ai.onnx.Mul:7)\n  1153 (ai.onnx.Mul:7)\n  1154 (ai.onnx.Sub:7)\n  1155 (ai.onnx.Mul:7)\n  1156 (ai.onnx.Add:7)\n  1157 (ai.onnx.MatMul:9)\n  1158 (ai.onnx.Add:7)\n  1159 (ai.onnx.Div:7)\n  1160 (ai.onnx.Erf:9)\n  1161 (ai.onnx.Add:7)\n  1162 (ai.onnx.Mul:7)\n  1163 (ai.onnx.Mul:7)\n  1164 (ai.onnx.MatMul:9)\n  1165 (ai.onnx.Add:7)\n  1166 (ai.onnx.Add:7)\n  1167 (ai.onnx.ReduceMean:11)\n  1168 (ai.onnx.Cast:9)\n  1169 (ai.onnx.Cast:9)\n  1170 (ai.onnx.Sub:7)\n  1171 (ai.onnx.Mul:7)\n  1172 (ai.onnx.ReduceMean:11)\n  1173 (ai.onnx.Cast:9)\n  1174 (ai.onnx.Add:7)\n  1175 (ai.onnx.Sqrt:6)\n  1176 (ai.onnx.Reciprocal:6)\n  1177 (ai.onnx.Mul:7)\n  1178 (ai.onnx.Mul:7)\n  1179 (ai.onnx.Sub:7)\n  1180 (ai.onnx.Mul:7)\n  1181 (ai.onnx.Add:7)\n  1182 (ai.onnx.MatMul:9)\n  1183 (ai.onnx.Add:7)\n  1184 (ai.onnx.Reshape:5)\n  1185 (ai.onnx.Transpose:1)\n  1186 (ai.onnx.MatMul:9)\n  1187 (ai.onnx.Add:7)\n  1188 (ai.onnx.Reshape:5)\n  1189 (ai.onnx.Transpose:1)\n  1190 (ai.onnx.MatMul:9)\n  1191 (ai.onnx.Add:7)\n  1192 (ai.onnx.Reshape:5)\n  1193 (ai.onnx.Transpose:1)\n  1194 (ai.onnx.MatMul:9)\n  1195 (ai.onnx.Mul:7)\n  1196 (ai.onnx.Add:7)\n  1197 (ai.onnx.Softmax:11)\n  1198 (ai.onnx.MatMul:9)\n  1199 (ai.onnx.Transpose:1)\n  1200 (ai.onnx.Reshape:5)\n  1201 (ai.onnx.MatMul:9)\n  1202 (ai.onnx.Add:7)\n  1203 (ai.onnx.Add:7)\n  1204 (ai.onnx.ReduceMean:11)\n  1205 (ai.onnx.Cast:9)\n  1206 (ai.onnx.Cast:9)\n  1207 (ai.onnx.Sub:7)\n  1208 (ai.onnx.Mul:7)\n  1209 (ai.onnx.ReduceMean:11)\n  1210 (ai.onnx.Cast:9)\n  1211 (ai.onnx.Add:7)\n  1212 (ai.onnx.Sqrt:6)\n  1213 (ai.onnx.Reciprocal:6)\n  1214 (ai.onnx.Mul:7)\n  1215 (ai.onnx.Mul:7)\n  1216 (ai.onnx.Sub:7)\n  1217 (ai.onnx.Mul:7)\n  1218 (ai.onnx.Add:7)\n  1219 (ai.onnx.MatMul:9)\n  1220 (ai.onnx.Add:7)\n  1221 (ai.onnx.Div:7)\n  1222 (ai.onnx.Erf:9)\n  1223 (ai.onnx.Add:7)\n  1224 (ai.onnx.Mul:7)\n  1225 (ai.onnx.Mul:7)\n  1226 (ai.onnx.MatMul:9)\n  1227 (ai.onnx.Add:7)\n  1228 (ai.onnx.Add:7)\n  1229 (ai.onnx.ReduceMean:11)\n  1230 (ai.onnx.Cast:9)\n  1231 (ai.onnx.Cast:9)\n  1232 (ai.onnx.Sub:7)\n  1233 (ai.onnx.Mul:7)\n  1234 (ai.onnx.ReduceMean:11)\n  1235 (ai.onnx.Cast:9)\n  1236 (ai.onnx.Add:7)\n  1237 (ai.onnx.Sqrt:6)\n  1238 (ai.onnx.Reciprocal:6)\n  1239 (ai.onnx.Mul:7)\n  1240 (ai.onnx.Mul:7)\n  1241 (ai.onnx.Sub:7)\n  1242 (ai.onnx.Mul:7)\n  1243 (ai.onnx.Add:7)\n  1244 (ai.onnx.MatMul:9)\n  1245 (ai.onnx.Add:7)\n  1246 (ai.onnx.Reshape:5)\n  1247 (ai.onnx.Transpose:1)\n  1248 (ai.onnx.MatMul:9)\n  1249 (ai.onnx.Add:7)\n  1250 (ai.onnx.Reshape:5)\n  1251 (ai.onnx.Transpose:1)\n  1252 (ai.onnx.MatMul:9)\n  1253 (ai.onnx.Add:7)\n  1254 (ai.onnx.Reshape:5)\n  1255 (ai.onnx.Transpose:1)\n  1256 (ai.onnx.MatMul:9)\n  1257 (ai.onnx.Mul:7)\n  1258 (ai.onnx.Add:7)\n  1259 (ai.onnx.Softmax:11)\n  1260 (ai.onnx.MatMul:9)\n  1261 (ai.onnx.Transpose:1)\n  1262 (ai.onnx.Reshape:5)\n  1263 (ai.onnx.MatMul:9)\n  1264 (ai.onnx.Add:7)\n  1265 (ai.onnx.Add:7)\n  1266 (ai.onnx.ReduceMean:11)\n  1267 (ai.onnx.Cast:9)\n  1268 (ai.onnx.Cast:9)\n  1269 (ai.onnx.Sub:7)\n  1270 (ai.onnx.Mul:7)\n  1271 (ai.onnx.ReduceMean:11)\n  1272 (ai.onnx.Cast:9)\n  1273 (ai.onnx.Add:7)\n  1274 (ai.onnx.Sqrt:6)\n  1275 (ai.onnx.Reciprocal:6)\n  1276 (ai.onnx.Mul:7)\n  1277 (ai.onnx.Mul:7)\n  1278 (ai.onnx.Sub:7)\n  1279 (ai.onnx.Mul:7)\n  1280 (ai.onnx.Add:7)\n  1281 (ai.onnx.MatMul:9)\n  1282 (ai.onnx.Add:7)\n  1283 (ai.onnx.Div:7)\n  1284 (ai.onnx.Erf:9)\n  1285 (ai.onnx.Add:7)\n  1286 (ai.onnx.Mul:7)\n  1287 (ai.onnx.Mul:7)\n  1288 (ai.onnx.MatMul:9)\n  1289 (ai.onnx.Add:7)\n  1290 (ai.onnx.Add:7)\n  1291 (ai.onnx.ReduceMean:11)\n  1292 (ai.onnx.Cast:9)\n  1293 (ai.onnx.Cast:9)\n  1294 (ai.onnx.Sub:7)\n  1295 (ai.onnx.Mul:7)\n  1296 (ai.onnx.ReduceMean:11)\n  1297 (ai.onnx.Cast:9)\n  1298 (ai.onnx.Add:7)\n  1299 (ai.onnx.Sqrt:6)\n  1300 (ai.onnx.Reciprocal:6)\n  1301 (ai.onnx.Mul:7)\n  1302 (ai.onnx.Mul:7)\n  1303 (ai.onnx.Sub:7)\n  1304 (ai.onnx.Mul:7)\n  1305 (ai.onnx.Add:7)\n  1306 (ai.onnx.MatMul:9)\n  1307 (ai.onnx.Add:7)\n  1308 (ai.onnx.Reshape:5)\n  1309 (ai.onnx.Transpose:1)\n  1310 (ai.onnx.MatMul:9)\n  1311 (ai.onnx.Add:7)\n  1312 (ai.onnx.Reshape:5)\n  1313 (ai.onnx.Transpose:1)\n  1314 (ai.onnx.MatMul:9)\n  1315 (ai.onnx.Add:7)\n  1316 (ai.onnx.Reshape:5)\n  1317 (ai.onnx.Transpose:1)\n  1318 (ai.onnx.MatMul:9)\n  1319 (ai.onnx.Mul:7)\n  1320 (ai.onnx.Add:7)\n  1321 (ai.onnx.Softmax:11)\n  1322 (ai.onnx.MatMul:9)\n  1323 (ai.onnx.Transpose:1)\n  1324 (ai.onnx.Reshape:5)\n  1325 (ai.onnx.MatMul:9)\n  1326 (ai.onnx.Add:7)\n  1327 (ai.onnx.Add:7)\n  1328 (ai.onnx.ReduceMean:11)\n  1329 (ai.onnx.Cast:9)\n  1330 (ai.onnx.Cast:9)\n  1331 (ai.onnx.Sub:7)\n  1332 (ai.onnx.Mul:7)\n  1333 (ai.onnx.ReduceMean:11)\n  1334 (ai.onnx.Cast:9)\n  1335 (ai.onnx.Add:7)\n  1336 (ai.onnx.Sqrt:6)\n  1337 (ai.onnx.Reciprocal:6)\n  1338 (ai.onnx.Mul:7)\n  1339 (ai.onnx.Mul:7)\n  1340 (ai.onnx.Sub:7)\n  1341 (ai.onnx.Mul:7)\n  1342 (ai.onnx.Add:7)\n  1343 (ai.onnx.MatMul:9)\n  1344 (ai.onnx.Add:7)\n  1345 (ai.onnx.Div:7)\n  1346 (ai.onnx.Erf:9)\n  1347 (ai.onnx.Add:7)\n  1348 (ai.onnx.Mul:7)\n  1349 (ai.onnx.Mul:7)\n  1350 (ai.onnx.MatMul:9)\n  1351 (ai.onnx.Add:7)\n  1352 (ai.onnx.Add:7)\n  1353 (ai.onnx.ReduceMean:11)\n  1354 (ai.onnx.Cast:9)\n  1355 (ai.onnx.Cast:9)\n  1356 (ai.onnx.Sub:7)\n  1357 (ai.onnx.Mul:7)\n  1358 (ai.onnx.ReduceMean:11)\n  1359 (ai.onnx.Cast:9)\n  1360 (ai.onnx.Add:7)\n  1361 (ai.onnx.Sqrt:6)\n  1362 (ai.onnx.Reciprocal:6)\n  1363 (ai.onnx.Mul:7)\n  1364 (ai.onnx.Mul:7)\n  1365 (ai.onnx.Sub:7)\n  1366 (ai.onnx.Mul:7)\n  1367 (ai.onnx.Add:7)\n  1368 (ai.onnx.MatMul:9)\n  1369 (ai.onnx.Add:7)\n  1370 (ai.onnx.Reshape:5)\n  1371 (ai.onnx.Transpose:1)\n  1372 (ai.onnx.MatMul:9)\n  1373 (ai.onnx.Add:7)\n  1374 (ai.onnx.Reshape:5)\n  1375 (ai.onnx.Transpose:1)\n  1376 (ai.onnx.MatMul:9)\n  1377 (ai.onnx.Add:7)\n  1378 (ai.onnx.Reshape:5)\n  1379 (ai.onnx.Transpose:1)\n  1380 (ai.onnx.MatMul:9)\n  1381 (ai.onnx.Mul:7)\n  1382 (ai.onnx.Add:7)\n  1383 (ai.onnx.Softmax:11)\n  1384 (ai.onnx.MatMul:9)\n  1385 (ai.onnx.Transpose:1)\n  1386 (ai.onnx.Reshape:5)\n  1387 (ai.onnx.MatMul:9)\n  1388 (ai.onnx.Add:7)\n  1389 (ai.onnx.Add:7)\n  1390 (ai.onnx.ReduceMean:11)\n  1391 (ai.onnx.Cast:9)\n  1392 (ai.onnx.Cast:9)\n  1393 (ai.onnx.Sub:7)\n  1394 (ai.onnx.Mul:7)\n  1395 (ai.onnx.ReduceMean:11)\n  1396 (ai.onnx.Cast:9)\n  1397 (ai.onnx.Add:7)\n  1398 (ai.onnx.Sqrt:6)\n  1399 (ai.onnx.Reciprocal:6)\n  1400 (ai.onnx.Mul:7)\n  1401 (ai.onnx.Mul:7)\n  1402 (ai.onnx.Sub:7)\n  1403 (ai.onnx.Mul:7)\n  1404 (ai.onnx.Add:7)\n  1405 (ai.onnx.MatMul:9)\n  1406 (ai.onnx.Add:7)\n  1407 (ai.onnx.Div:7)\n  1408 (ai.onnx.Erf:9)\n  1409 (ai.onnx.Add:7)\n  1410 (ai.onnx.Mul:7)\n  1411 (ai.onnx.Mul:7)\n  1412 (ai.onnx.MatMul:9)\n  1413 (ai.onnx.Add:7)\n  1414 (ai.onnx.Add:7)\n  1415 (ai.onnx.ReduceMean:11)\n  1416 (ai.onnx.Cast:9)\n  1417 (ai.onnx.Cast:9)\n  1418 (ai.onnx.Sub:7)\n  1419 (ai.onnx.Mul:7)\n  1420 (ai.onnx.ReduceMean:11)\n  1421 (ai.onnx.Cast:9)\n  1422 (ai.onnx.Add:7)\n  1423 (ai.onnx.Sqrt:6)\n  1424 (ai.onnx.Reciprocal:6)\n  1425 (ai.onnx.Mul:7)\n  1426 (ai.onnx.Mul:7)\n  1427 (ai.onnx.Sub:7)\n  1428 (ai.onnx.Mul:7)\n  1429 (ai.onnx.Add:7)\n  1430 (ai.onnx.MatMul:9)\n  1431 (ai.onnx.Add:7)\n  1432 (ai.onnx.Reshape:5)\n  1433 (ai.onnx.Transpose:1)\n  1434 (ai.onnx.MatMul:9)\n  1435 (ai.onnx.Add:7)\n  1436 (ai.onnx.Reshape:5)\n  1437 (ai.onnx.Transpose:1)\n  1438 (ai.onnx.MatMul:9)\n  1439 (ai.onnx.Add:7)\n  1440 (ai.onnx.Reshape:5)\n  1441 (ai.onnx.Transpose:1)\n  1442 (ai.onnx.MatMul:9)\n  1443 (ai.onnx.Mul:7)\n  1444 (ai.onnx.Add:7)\n  1445 (ai.onnx.Softmax:11)\n  1446 (ai.onnx.MatMul:9)\n  1447 (ai.onnx.Transpose:1)\n  1448 (ai.onnx.Reshape:5)\n  1449 (ai.onnx.MatMul:9)\n  1450 (ai.onnx.Add:7)\n  1451 (ai.onnx.Add:7)\n  1452 (ai.onnx.ReduceMean:11)\n  1453 (ai.onnx.Cast:9)\n  1454 (ai.onnx.Cast:9)\n  1455 (ai.onnx.Sub:7)\n  1456 (ai.onnx.Mul:7)\n  1457 (ai.onnx.ReduceMean:11)\n  1458 (ai.onnx.Cast:9)\n  1459 (ai.onnx.Add:7)\n  1460 (ai.onnx.Sqrt:6)\n  1461 (ai.onnx.Reciprocal:6)\n  1462 (ai.onnx.Mul:7)\n  1463 (ai.onnx.Mul:7)\n  1464 (ai.onnx.Sub:7)\n  1465 (ai.onnx.Mul:7)\n  1466 (ai.onnx.Add:7)\n  1467 (ai.onnx.MatMul:9)\n  1468 (ai.onnx.Add:7)\n  1469 (ai.onnx.Div:7)\n  1470 (ai.onnx.Erf:9)\n  1471 (ai.onnx.Add:7)\n  1472 (ai.onnx.Mul:7)\n  1473 (ai.onnx.Mul:7)\n  1474 (ai.onnx.MatMul:9)\n  1475 (ai.onnx.Add:7)\n  1476 (ai.onnx.Add:7)\n  1477 (ai.onnx.ReduceMean:11)\n  1478 (ai.onnx.Cast:9)\n  1479 (ai.onnx.Cast:9)\n  1480 (ai.onnx.Sub:7)\n  1481 (ai.onnx.Mul:7)\n  1482 (ai.onnx.ReduceMean:11)\n  1483 (ai.onnx.Cast:9)\n  1484 (ai.onnx.Add:7)\n  1485 (ai.onnx.Sqrt:6)\n  1486 (ai.onnx.Reciprocal:6)\n  1487 (ai.onnx.Mul:7)\n  1488 (ai.onnx.Mul:7)\n  1489 (ai.onnx.Sub:7)\n  1490 (ai.onnx.Mul:7)\n  1491 (ai.onnx.Add:7)\n  1492 (ai.onnx.MatMul:9)\n  1493 (ai.onnx.Add:7)\n  1494 (ai.onnx.Reshape:5)\n  1495 (ai.onnx.Transpose:1)\n  1496 (ai.onnx.MatMul:9)\n  1497 (ai.onnx.Add:7)\n  1498 (ai.onnx.Reshape:5)\n  1499 (ai.onnx.Transpose:1)\n  1500 (ai.onnx.MatMul:9)\n  1501 (ai.onnx.Add:7)\n  1502 (ai.onnx.Reshape:5)\n  1503 (ai.onnx.Transpose:1)\n  1504 (ai.onnx.MatMul:9)\n  1505 (ai.onnx.Mul:7)\n  1506 (ai.onnx.Add:7)\n  1507 (ai.onnx.Softmax:11)\n  1508 (ai.onnx.MatMul:9)\n  1509 (ai.onnx.Transpose:1)\n  1510 (ai.onnx.Reshape:5)\n  1511 (ai.onnx.MatMul:9)\n  1512 (ai.onnx.Add:7)\n  1513 (ai.onnx.Add:7)\n  1514 (ai.onnx.ReduceMean:11)\n  1515 (ai.onnx.Cast:9)\n  1516 (ai.onnx.Cast:9)\n  1517 (ai.onnx.Sub:7)\n  1518 (ai.onnx.Mul:7)\n  1519 (ai.onnx.ReduceMean:11)\n  1520 (ai.onnx.Cast:9)\n  1521 (ai.onnx.Add:7)\n  1522 (ai.onnx.Sqrt:6)\n  1523 (ai.onnx.Reciprocal:6)\n  1524 (ai.onnx.Mul:7)\n  1525 (ai.onnx.Mul:7)\n  1526 (ai.onnx.Sub:7)\n  1527 (ai.onnx.Mul:7)\n  1528 (ai.onnx.Add:7)\n  1529 (ai.onnx.MatMul:9)\n  1530 (ai.onnx.Add:7)\n  1531 (ai.onnx.Div:7)\n  1532 (ai.onnx.Erf:9)\n  1533 (ai.onnx.Add:7)\n  1534 (ai.onnx.Mul:7)\n  1535 (ai.onnx.Mul:7)\n  1536 (ai.onnx.MatMul:9)\n  1537 (ai.onnx.Add:7)\n  1538 (ai.onnx.Add:7)\n  1539 (ai.onnx.ReduceMean:11)\n  1540 (ai.onnx.Cast:9)\n  1541 (ai.onnx.Cast:9)\n  1542 (ai.onnx.Sub:7)\n  1543 (ai.onnx.Mul:7)\n  1544 (ai.onnx.ReduceMean:11)\n  1545 (ai.onnx.Cast:9)\n  1546 (ai.onnx.Add:7)\n  1547 (ai.onnx.Sqrt:6)\n  1548 (ai.onnx.Reciprocal:6)\n  1549 (ai.onnx.Mul:7)\n  1550 (ai.onnx.Mul:7)\n  1551 (ai.onnx.Sub:7)\n  1552 (ai.onnx.Mul:7)\n  1553 (ai.onnx.Add:7)\n  1554 (ai.onnx.MatMul:9)\n  1555 (ai.onnx.Add:7)\n  1556 (ai.onnx.Reshape:5)\n  1557 (ai.onnx.Transpose:1)\n  1558 (ai.onnx.MatMul:9)\n  1559 (ai.onnx.Add:7)\n  1560 (ai.onnx.Reshape:5)\n  1561 (ai.onnx.Transpose:1)\n  1562 (ai.onnx.MatMul:9)\n  1563 (ai.onnx.Add:7)\n  1564 (ai.onnx.Reshape:5)\n  1565 (ai.onnx.Transpose:1)\n  1566 (ai.onnx.MatMul:9)\n  1567 (ai.onnx.Mul:7)\n  1568 (ai.onnx.Add:7)\n  1569 (ai.onnx.Softmax:11)\n  1570 (ai.onnx.MatMul:9)\n  1571 (ai.onnx.Transpose:1)\n  1572 (ai.onnx.Reshape:5)\n  1573 (ai.onnx.MatMul:9)\n  1574 (ai.onnx.Add:7)\n  1575 (ai.onnx.Add:7)\n  1576 (ai.onnx.ReduceMean:11)\n  1577 (ai.onnx.Cast:9)\n  1578 (ai.onnx.Cast:9)\n  1579 (ai.onnx.Sub:7)\n  1580 (ai.onnx.Mul:7)\n  1581 (ai.onnx.ReduceMean:11)\n  1582 (ai.onnx.Cast:9)\n  1583 (ai.onnx.Add:7)\n  1584 (ai.onnx.Sqrt:6)\n  1585 (ai.onnx.Reciprocal:6)\n  1586 (ai.onnx.Mul:7)\n  1587 (ai.onnx.Mul:7)\n  1588 (ai.onnx.Sub:7)\n  1589 (ai.onnx.Mul:7)\n  1590 (ai.onnx.Add:7)\n  1591 (ai.onnx.MatMul:9)\n  1592 (ai.onnx.Add:7)\n  1593 (ai.onnx.Div:7)\n  1594 (ai.onnx.Erf:9)\n  1595 (ai.onnx.Add:7)\n  1596 (ai.onnx.Mul:7)\n  1597 (ai.onnx.Mul:7)\n  1598 (ai.onnx.MatMul:9)\n  1599 (ai.onnx.Add:7)\n  1600 (ai.onnx.Add:7)\n  1601 (ai.onnx.ReduceMean:11)\n  1602 (ai.onnx.Cast:9)\n  1603 (ai.onnx.Cast:9)\n  1604 (ai.onnx.Sub:7)\n  1605 (ai.onnx.Mul:7)\n  1606 (ai.onnx.ReduceMean:11)\n  1607 (ai.onnx.Cast:9)\n  1608 (ai.onnx.Add:7)\n  1609 (ai.onnx.Sqrt:6)\n  1610 (ai.onnx.Reciprocal:6)\n  1611 (ai.onnx.Mul:7)\n  1612 (ai.onnx.Mul:7)\n  1613 (ai.onnx.Sub:7)\n  1614 (ai.onnx.Mul:7)\n  1615 (ai.onnx.Add:7)\n  1616 (ai.onnx.MatMul:9)\n  1617 (ai.onnx.Add:7)\n  1618 (ai.onnx.Reshape:5)\n  1619 (ai.onnx.Transpose:1)\n  1620 (ai.onnx.MatMul:9)\n  1621 (ai.onnx.Add:7)\n  1622 (ai.onnx.Reshape:5)\n  1623 (ai.onnx.Transpose:1)\n  1624 (ai.onnx.MatMul:9)\n  1625 (ai.onnx.Add:7)\n  1626 (ai.onnx.Reshape:5)\n  1627 (ai.onnx.Transpose:1)\n  1628 (ai.onnx.MatMul:9)\n  1629 (ai.onnx.Mul:7)\n  1630 (ai.onnx.Add:7)\n  1631 (ai.onnx.Softmax:11)\n  1632 (ai.onnx.MatMul:9)\n  1633 (ai.onnx.Transpose:1)\n  1634 (ai.onnx.Reshape:5)\n  1635 (ai.onnx.MatMul:9)\n  1636 (ai.onnx.Add:7)\n  1637 (ai.onnx.Add:7)\n  1638 (ai.onnx.ReduceMean:11)\n  1639 (ai.onnx.Cast:9)\n  1640 (ai.onnx.Cast:9)\n  1641 (ai.onnx.Sub:7)\n  1642 (ai.onnx.Mul:7)\n  1643 (ai.onnx.ReduceMean:11)\n  1644 (ai.onnx.Cast:9)\n  1645 (ai.onnx.Add:7)\n  1646 (ai.onnx.Sqrt:6)\n  1647 (ai.onnx.Reciprocal:6)\n  1648 (ai.onnx.Mul:7)\n  1649 (ai.onnx.Mul:7)\n  1650 (ai.onnx.Sub:7)\n  1651 (ai.onnx.Mul:7)\n  1652 (ai.onnx.Add:7)\n  1653 (ai.onnx.MatMul:9)\n  1654 (ai.onnx.Add:7)\n  1655 (ai.onnx.Div:7)\n  1656 (ai.onnx.Erf:9)\n  1657 (ai.onnx.Add:7)\n  1658 (ai.onnx.Mul:7)\n  1659 (ai.onnx.Mul:7)\n  1660 (ai.onnx.MatMul:9)\n  1661 (ai.onnx.Add:7)\n  1662 (ai.onnx.Add:7)\n  1663 (ai.onnx.ReduceMean:11)\n  1664 (ai.onnx.Cast:9)\n  1665 (ai.onnx.Cast:9)\n  1666 (ai.onnx.Sub:7)\n  1667 (ai.onnx.Mul:7)\n  1668 (ai.onnx.ReduceMean:11)\n  1669 (ai.onnx.Cast:9)\n  1670 (ai.onnx.Add:7)\n  1671 (ai.onnx.Sqrt:6)\n  1672 (ai.onnx.Reciprocal:6)\n  1673 (ai.onnx.Mul:7)\n  1674 (ai.onnx.Mul:7)\n  1675 (ai.onnx.Sub:7)\n  1676 (ai.onnx.Mul:7)\n  1677 (ai.onnx.Add:7)\n  1678 (ai.onnx.MatMul:9)\n  1679 (ai.onnx.Add:7)\n  1680 (ai.onnx.Reshape:5)\n  1681 (ai.onnx.Transpose:1)\n  1682 (ai.onnx.MatMul:9)\n  1683 (ai.onnx.Add:7)\n  1684 (ai.onnx.Reshape:5)\n  1685 (ai.onnx.Transpose:1)\n  1686 (ai.onnx.MatMul:9)\n  1687 (ai.onnx.Add:7)\n  1688 (ai.onnx.Reshape:5)\n  1689 (ai.onnx.Transpose:1)\n  1690 (ai.onnx.MatMul:9)\n  1691 (ai.onnx.Mul:7)\n  1692 (ai.onnx.Add:7)\n  1693 (ai.onnx.Softmax:11)\n  1694 (ai.onnx.MatMul:9)\n  1695 (ai.onnx.Transpose:1)\n  1696 (ai.onnx.Reshape:5)\n  1697 (ai.onnx.MatMul:9)\n  1698 (ai.onnx.Add:7)\n  1699 (ai.onnx.Add:7)\n  1700 (ai.onnx.ReduceMean:11)\n  1701 (ai.onnx.Cast:9)\n  1702 (ai.onnx.Cast:9)\n  1703 (ai.onnx.Sub:7)\n  1704 (ai.onnx.Mul:7)\n  1705 (ai.onnx.ReduceMean:11)\n  1706 (ai.onnx.Cast:9)\n  1707 (ai.onnx.Add:7)\n  1708 (ai.onnx.Sqrt:6)\n  1709 (ai.onnx.Reciprocal:6)\n  1710 (ai.onnx.Mul:7)\n  1711 (ai.onnx.Mul:7)\n  1712 (ai.onnx.Sub:7)\n  1713 (ai.onnx.Mul:7)\n  1714 (ai.onnx.Add:7)\n  1715 (ai.onnx.MatMul:9)\n  1716 (ai.onnx.Add:7)\n  1717 (ai.onnx.Div:7)\n  1718 (ai.onnx.Erf:9)\n  1719 (ai.onnx.Add:7)\n  1720 (ai.onnx.Mul:7)\n  1721 (ai.onnx.Mul:7)\n  1722 (ai.onnx.MatMul:9)\n  1723 (ai.onnx.Add:7)\n  1724 (ai.onnx.Add:7)\n  1725 (ai.onnx.ReduceMean:11)\n  1726 (ai.onnx.Cast:9)\n  1727 (ai.onnx.Cast:9)\n  1728 (ai.onnx.Sub:7)\n  1729 (ai.onnx.Mul:7)\n  1730 (ai.onnx.ReduceMean:11)\n  1731 (ai.onnx.Cast:9)\n  1732 (ai.onnx.Add:7)\n  1733 (ai.onnx.Sqrt:6)\n  1734 (ai.onnx.Reciprocal:6)\n  1735 (ai.onnx.Mul:7)\n  1736 (ai.onnx.Mul:7)\n  1737 (ai.onnx.Sub:7)\n  1738 (ai.onnx.Mul:7)\n  1739 (ai.onnx.Add:7)\n  1740 (ai.onnx.Reshape:5)\n  1741 (ai.onnx.Slice:11)\n  1742 (ai.onnx.Reshape:5)\n  1743 (ai.onnx.MatMul:9)\n  1744 (ai.onnx.Add:7)\n  1745 (ai.onnx.Tanh:6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mpopart_exception\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-fed0f36b798c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-0b592e380a0f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(builder, opts, batch_size, batch_per_step, n_sample)\u001b[0m\n\u001b[1;32m     35\u001b[0m     session = popart.InferenceSession(builder.getModelProto(), dataflow, device, \n\u001b[1;32m     36\u001b[0m                                     \u001b[0minputShapeInfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputShapeInfo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                                     userOptions=opts)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepareDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/scratch001/custeng-cn-scratch/yongxiy/sdk/poplar_sdk-ubuntu_18_04-2.1.0-EA.1+539-af8454999a/popart-ubuntu_18_04-2.1.0+124588-d0630ea3a6/python/popart/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fnModel, dataFlow, deviceInfo, inputShapeInfo, patterns, userOptions)\u001b[0m\n\u001b[1;32m    137\u001b[0m         super(InferenceSession,\n\u001b[1;32m    138\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeviceInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputShapeInfo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                              userOptions, patterns)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFlow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataFlow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mpopart_exception\u001b[0m: Either all Ops in the main graph must have their virtual graph ids set, or none must. Op count per virtual graph id\n  -1 : 790\n  0 : 790\n  1 : 42\nOps with no virtual graph id :  \n  101 (ai.onnx.Reshape:5)\n  106 (ai.onnx.Expand:8)\n  109 (ai.onnx.Reshape:5)\n  110 (ai.onnx.Gather:11)\n  115 (ai.onnx.Reshape:5)\n  120 (ai.onnx.Equal:11)\n  121 (ai.onnx.Not:1)\n  122 (ai.onnx.Cast:9)\n  123 (ai.onnx.ReduceSum:11)\n  124 (ai.onnx.Reshape:5)\n  125 (ai.onnx.Cast:9)\n  126 (ai.onnx.Cast:9)\n  127 (ai.onnx.Less:9)\n  128 (ai.onnx.Cast:9)\n  129 (ai.onnx.Reshape:5)\n  130 (ai.onnx.Mul:7)\n  131 (ai.onnx.Reshape:5)\n  132 (ai.onnx.Sub:7)\n  133 (ai.onnx.Mul:7)\n  963 (ai.onnx.OneHot:11)\n  964 (ai.onnx.MatMul:9)\n  965 (ai.onnx.Reshape:5)\n  966 (ai.onnx.Add:7)\n  967 (ai.onnx.Add:7)\n  968 (ai.onnx.ReduceMean:11)\n  969 (ai.onnx.Cast:9)\n  970 (ai.onnx.Cast:9)\n  971 (ai.onnx.Sub:7)\n  972 (ai.onnx.Mul:7)\n  973 (ai.onnx.GlobalAveragePool:1)\n  974 (ai.onnx.Cast:9)\n  975 (ai.onnx.Add:7)\n  976 (ai.onnx.Sqrt:6)\n  977 (ai.onnx.Reciprocal:6)\n  978 (ai.onnx.Mul:7)\n  979 (ai.onnx.Mul:7)\n  980 (ai.onnx.Sub:7)\n  981 (ai.onnx.Mul:7)\n  982 (ai.onnx.Add:7)\n  995 (ai.onnx.Reshape:5)\n  996 (ai.onnx.MatMul:9)\n  997 (ai.onnx.Add:7)\n  998 (ai.onnx.Reshape:5)\n  999 (ai.onnx.Transpose:1)\n  1000 (ai.onnx.MatMul:9)\n  1001 (ai.onnx.Add:7)\n  1002 (ai.onnx.Reshape:5)\n  1003 (ai.onnx.Transpose:1)\n  1004 (ai.onnx.MatMul:9)\n  1005 (ai.onnx.Add:7)\n  1006 (ai.onnx.Reshape:5)\n  1007 (ai.onnx.Transpose:1)\n  1008 (ai.onnx.MatMul:9)\n  1009 (ai.onnx.Mul:7)\n  1010 (ai.onnx.Add:7)\n  1011 (ai.onnx.Softmax:11)\n  1012 (ai.onnx.MatMul:9)\n  1013 (ai.onnx.Transpose:1)\n  1014 (ai.onnx.Reshape:5)\n  1015 (ai.onnx.MatMul:9)\n  1016 (ai.onnx.Add:7)\n  1017 (ai.onnx.Add:7)\n  1018 (ai.onnx.ReduceMean:11)\n  1019 (ai.onnx.Cast:9)\n  1020 (ai.onnx.Cast:9)\n  1021 (ai.onnx.Sub:7)\n  1022 (ai.onnx.Mul:7)\n  1023 (ai.onnx.ReduceMean:11)\n  1024 (ai.onnx.Cast:9)\n  1025 (ai.onnx.Add:7)\n  1026 (ai.onnx.Sqrt:6)\n  1027 (ai.onnx.Reciprocal:6)\n  1028 (ai.onnx.Mul:7)\n  1029 (ai.onnx.Mul:7)\n  1030 (ai.onnx.Sub:7)\n  1031 (ai.onnx.Mul:7)\n  1032 (ai.onnx.Add:7)\n  1033 (ai.onnx.MatMul:9)\n  1034 (ai.onnx.Add:7)\n  1035 (ai.onnx.Div:7)\n  1036 (ai.onnx.Erf:9)\n  1037 (ai.onnx.Add:7)\n  1038 (ai.onnx.Mul:7)\n  1039 (ai.onnx.Mul:7)\n  1040 (ai.onnx.MatMul:9)\n  1041 (ai.onnx.Add:7)\n  1042 (ai.onnx.Add:7)\n  1043 (ai.onnx.ReduceMean:11)\n  1044 (ai.onnx.Cast:9)\n  1045 (ai.onnx.Cast:9)\n  1046 (ai.onnx.Sub:7)\n  1047 (ai.onnx.Mul:7)\n  1048 (ai.onnx.ReduceMean:11)\n  1049 (ai.onnx.Cast:9)\n  1050 (ai.onnx.Add:7)\n  1051 (ai.onnx.Sqrt:6)\n  1052 (ai.onnx.Reciprocal:6)\n  1053 (ai.onnx.Mul:7)\n  1054 (ai.onnx.Mul:7)\n  1055 (ai.onnx.Sub:7)\n  1056 (ai.onnx.Mul:7)\n  1057 (ai.onnx.Add:7)\n  1058 (ai.onnx.MatMul:9)\n  1059 (ai.onnx.Add:7)\n  1060 (ai.onnx.Reshape:5)\n  1061 (ai.onnx.Transpose:1)\n  1062 (ai.onnx.MatMul:9)\n  1063 (ai.onnx.Add:7)\n  1064 (ai.onnx.Reshape:5)\n  1065 (ai.onnx.Transpose:1)\n  1066 (ai.onnx.MatMul:9)\n  1067 (ai.onnx.Add:7)\n  1068 (ai.onnx.Reshape:5)\n  1069 (ai.onnx.Transpose:1)\n  1070 (ai.onnx.MatMul:9)\n  1071 (ai.onnx.Mul:7)\n  1072 (ai.onnx.Add:7)\n  1073 (ai.onnx.Softmax:11)\n  1074 (ai.onnx.MatMul:9)\n  1075 (ai.onnx.Transpose:1)\n  1076 (ai.onnx.Reshape:5)\n  1077 (ai.onnx.MatMul:9)\n  1078 (ai.onnx.Add:7)\n  1079 (ai.onnx.Add:7)\n  1080 (ai.onnx.ReduceMean:11)\n  1081 (ai.onnx.Cast:9)\n  1082 (ai.onnx.Cast:9)\n  1083 (ai.onnx.Sub:7)\n  1084 (ai.onnx.Mul:7)\n  1085 (ai.onnx.ReduceMean:11)\n  1086 (ai.onnx.Cast:9)\n  1087 (ai.onnx.Add:7)\n  1088 (ai.onnx.Sqrt:6)\n  1089 (ai.onnx.Reciprocal:6)\n  1090 (ai.onnx.Mul:7)\n  1091 (ai.onnx.Mul:7)\n  1092 (ai.onnx.Sub:7)\n  1093 (ai.onnx.Mul:7)\n  1094 (ai.onnx.Add:7)\n  1095 (ai.onnx.MatMul:9)\n  1096 (ai.onnx.Add:7)\n  1097 (ai.onnx.Div:7)\n  1098 (ai.onnx.Erf:9)\n  1099 (ai.onnx.Add:7)\n  1100 (ai.onnx.Mul:7)\n  1101 (ai.onnx.Mul:7)\n  1102 (ai.onnx.MatMul:9)\n  1103 (ai.onnx.Add:7)\n  1104 (ai.onnx.Add:7)\n  1105 (ai.onnx.ReduceMean:11)\n  1106 (ai.onnx.Cast:9)\n  1107 (ai.onnx.Cast:9)\n  1108 (ai.onnx.Sub:7)\n  1109 (ai.onnx.Mul:7)\n  1110 (ai.onnx.ReduceMean:11)\n  1111 (ai.onnx.Cast:9)\n  1112 (ai.onnx.Add:7)\n  1113 (ai.onnx.Sqrt:6)\n  1114 (ai.onnx.Reciprocal:6)\n  1115 (ai.onnx.Mul:7)\n  1116 (ai.onnx.Mul:7)\n  1117 (ai.onnx.Sub:7)\n  1118 (ai.onnx.Mul:7)\n  1119 (ai.onnx.Add:7)\n  1120 (ai.onnx.MatMul:9)\n  1121 (ai.onnx.Add:7)\n  1122 (ai.onnx.Reshape:5)\n  1123 (ai.onnx.Transpose:1)\n  1124 (ai.onnx.MatMul:9)\n  1125 (ai.onnx.Add:7)\n  1126 (ai.onnx.Reshape:5)\n  1127 (ai.onnx.Transpose:1)\n  1128 (ai.onnx.MatMul:9)\n  1129 (ai.onnx.Add:7)\n  1130 (ai.onnx.Reshape:5)\n  1131 (ai.onnx.Transpose:1)\n  1132 (ai.onnx.MatMul:9)\n  1133 (ai.onnx.Mul:7)\n  1134 (ai.onnx.Add:7)\n  1135 (ai.onnx.Softmax:11)\n  1136 (ai.onnx.MatMul:9)\n  1137 (ai.onnx.Transpose:1)\n  1138 (ai.onnx.Reshape:5)\n  1139 (ai.onnx.MatMul:9)\n  1140 (ai.onnx.Add:7)\n  1141 (ai.onnx.Add:7)\n  1142 (ai.onnx.ReduceMean:11)\n  1143 (ai.onnx.Cast:9)\n  1144 (ai.onnx.Cast:9)\n  1145 (ai.onnx.Sub:7)\n  1146 (ai.onnx.Mul:7)\n  1147 (ai.onnx.ReduceMean:11)\n  1148 (ai.onnx.Cast:9)\n  1149 (ai.onnx.Add:7)\n  1150 (ai.onnx.Sqrt:6)\n  1151 (ai.onnx.Reciprocal:6)\n  1152 (ai.onnx.Mul:7)\n  1153 (ai.onnx.Mul:7)\n  1154 (ai.onnx.Sub:7)\n  1155 (ai.onnx.Mul:7)\n  1156 (ai.onnx.Add:7)\n  1157 (ai.onnx.MatMul:9)\n  1158 (ai.onnx.Add:7)\n  1159 (ai.onnx.Div:7)\n  1160 (ai.onnx.Erf:9)\n  1161 (ai.onnx.Add:7)\n  1162 (ai.onnx.Mul:7)\n  1163 (ai.onnx.Mul:7)\n  1164 (ai.onnx.MatMul:9)\n  1165 (ai.onnx.Add:7)\n  1166 (ai.onnx.Add:7)\n  1167 (ai.onnx.ReduceMean:11)\n  1168 (ai.onnx.Cast:9)\n  1169 (ai.onnx.Cast:9)\n  1170 (ai.onnx.Sub:7)\n  1171 (ai.onnx.Mul:7)\n  1172 (ai.onnx.ReduceMean:11)\n  1173 (ai.onnx.Cast:9)\n  1174 (ai.onnx.Add:7)\n  1175 (ai.onnx.Sqrt:6)\n  1176 (ai.onnx.Reciprocal:6)\n  1177 (ai.onnx.Mul:7)\n  1178 (ai.onnx.Mul:7)\n  1179 (ai.onnx.Sub:7)\n  1180 (ai.onnx.Mul:7)\n  1181 (ai.onnx.Add:7)\n  1182 (ai.onnx.MatMul:9)\n  1183 (ai.onnx.Add:7)\n  1184 (ai.onnx.Reshape:5)\n  1185 (ai.onnx.Transpose:1)\n  1186 (ai.onnx.MatMul:9)\n  1187 (ai.onnx.Add:7)\n  1188 (ai.onnx.Reshape:5)\n  1189 (ai.onnx.Transpose:1)\n  1190 (ai.onnx.MatMul:9)\n  1191 (ai.onnx.Add:7)\n  1192 (ai.onnx.Reshape:5)\n  1193 (ai.onnx.Transpose:1)\n  1194 (ai.onnx.MatMul:9)\n  1195 (ai.onnx.Mul:7)\n  1196 (ai.onnx.Add:7)\n  1197 (ai.onnx.Softmax:11)\n  1198 (ai.onnx.MatMul:9)\n  1199 (ai.onnx.Transpose:1)\n  1200 (ai.onnx.Reshape:5)\n  1201 (ai.onnx.MatMul:9)\n  1202 (ai.onnx.Add:7)\n  1203 (ai.onnx.Add:7)\n  1204 (ai.onnx.ReduceMean:11)\n  1205 (ai.onnx.Cast:9)\n  1206 (ai.onnx.Cast:9)\n  1207 (ai.onnx.Sub:7)\n  1208 (ai.onnx.Mul:7)\n  1209 (ai.onnx.ReduceMean:11)\n  1210 (ai.onnx.Cast:9)\n  1211 (ai.onnx.Add:7)\n  1212 (ai.onnx.Sqrt:6)\n  1213 (ai.onnx.Reciprocal:6)\n  1214 (ai.onnx.Mul:7)\n  1215 (ai.onnx.Mul:7)\n  1216 (ai.onnx.Sub:7)\n  1217 (ai.onnx.Mul:7)\n  1218 (ai.onnx.Add:7)\n  1219 (ai.onnx.MatMul:9)\n  1220 (ai.onnx.Add:7)\n  1221 (ai.onnx.Div:7)\n  1222 (ai.onnx.Erf:9)\n  1223 (ai.onnx.Add:7)\n  1224 (ai.onnx.Mul:7)\n  1225 (ai.onnx.Mul:7)\n  1226 (ai.onnx.MatMul:9)\n  1227 (ai.onnx.Add:7)\n  1228 (ai.onnx.Add:7)\n  1229 (ai.onnx.ReduceMean:11)\n  1230 (ai.onnx.Cast:9)\n  1231 (ai.onnx.Cast:9)\n  1232 (ai.onnx.Sub:7)\n  1233 (ai.onnx.Mul:7)\n  1234 (ai.onnx.ReduceMean:11)\n  1235 (ai.onnx.Cast:9)\n  1236 (ai.onnx.Add:7)\n  1237 (ai.onnx.Sqrt:6)\n  1238 (ai.onnx.Reciprocal:6)\n  1239 (ai.onnx.Mul:7)\n  1240 (ai.onnx.Mul:7)\n  1241 (ai.onnx.Sub:7)\n  1242 (ai.onnx.Mul:7)\n  1243 (ai.onnx.Add:7)\n  1244 (ai.onnx.MatMul:9)\n  1245 (ai.onnx.Add:7)\n  1246 (ai.onnx.Reshape:5)\n  1247 (ai.onnx.Transpose:1)\n  1248 (ai.onnx.MatMul:9)\n  1249 (ai.onnx.Add:7)\n  1250 (ai.onnx.Reshape:5)\n  1251 (ai.onnx.Transpose:1)\n  1252 (ai.onnx.MatMul:9)\n  1253 (ai.onnx.Add:7)\n  1254 (ai.onnx.Reshape:5)\n  1255 (ai.onnx.Transpose:1)\n  1256 (ai.onnx.MatMul:9)\n  1257 (ai.onnx.Mul:7)\n  1258 (ai.onnx.Add:7)\n  1259 (ai.onnx.Softmax:11)\n  1260 (ai.onnx.MatMul:9)\n  1261 (ai.onnx.Transpose:1)\n  1262 (ai.onnx.Reshape:5)\n  1263 (ai.onnx.MatMul:9)\n  1264 (ai.onnx.Add:7)\n  1265 (ai.onnx.Add:7)\n  1266 (ai.onnx.ReduceMean:11)\n  1267 (ai.onnx.Cast:9)\n  1268 (ai.onnx.Cast:9)\n  1269 (ai.onnx.Sub:7)\n  1270 (ai.onnx.Mul:7)\n  1271 (ai.onnx.ReduceMean:11)\n  1272 (ai.onnx.Cast:9)\n  1273 (ai.onnx.Add:7)\n  1274 (ai.onnx.Sqrt:6)\n  1275 (ai.onnx.Reciprocal:6)\n  1276 (ai.onnx.Mul:7)\n  1277 (ai.onnx.Mul:7)\n  1278 (ai.onnx.Sub:7)\n  1279 (ai.onnx.Mul:7)\n  1280 (ai.onnx.Add:7)\n  1281 (ai.onnx.MatMul:9)\n  1282 (ai.onnx.Add:7)\n  1283 (ai.onnx.Div:7)\n  1284 (ai.onnx.Erf:9)\n  1285 (ai.onnx.Add:7)\n  1286 (ai.onnx.Mul:7)\n  1287 (ai.onnx.Mul:7)\n  1288 (ai.onnx.MatMul:9)\n  1289 (ai.onnx.Add:7)\n  1290 (ai.onnx.Add:7)\n  1291 (ai.onnx.ReduceMean:11)\n  1292 (ai.onnx.Cast:9)\n  1293 (ai.onnx.Cast:9)\n  1294 (ai.onnx.Sub:7)\n  1295 (ai.onnx.Mul:7)\n  1296 (ai.onnx.ReduceMean:11)\n  1297 (ai.onnx.Cast:9)\n  1298 (ai.onnx.Add:7)\n  1299 (ai.onnx.Sqrt:6)\n  1300 (ai.onnx.Reciprocal:6)\n  1301 (ai.onnx.Mul:7)\n  1302 (ai.onnx.Mul:7)\n  1303 (ai.onnx.Sub:7)\n  1304 (ai.onnx.Mul:7)\n  1305 (ai.onnx.Add:7)\n  1306 (ai.onnx.MatMul:9)\n  1307 (ai.onnx.Add:7)\n  1308 (ai.onnx.Reshape:5)\n  1309 (ai.onnx.Transpose:1)\n  1310 (ai.onnx.MatMul:9)\n  1311 (ai.onnx.Add:7)\n  1312 (ai.onnx.Reshape:5)\n  1313 (ai.onnx.Transpose:1)\n  1314 (ai.onnx.MatMul:9)\n  1315 (ai.onnx.Add:7)\n  1316 (ai.onnx.Reshape:5)\n  1317 (ai.onnx.Transpose:1)\n  1318 (ai.onnx.MatMul:9)\n  1319 (ai.onnx.Mul:7)\n  1320 (ai.onnx.Add:7)\n  1321 (ai.onnx.Softmax:11)\n  1322 (ai.onnx.MatMul:9)\n  1323 (ai.onnx.Transpose:1)\n  1324 (ai.onnx.Reshape:5)\n  1325 (ai.onnx.MatMul:9)\n  1326 (ai.onnx.Add:7)\n  1327 (ai.onnx.Add:7)\n  1328 (ai.onnx.ReduceMean:11)\n  1329 (ai.onnx.Cast:9)\n  1330 (ai.onnx.Cast:9)\n  1331 (ai.onnx.Sub:7)\n  1332 (ai.onnx.Mul:7)\n  1333 (ai.onnx.ReduceMean:11)\n  1334 (ai.onnx.Cast:9)\n  1335 (ai.onnx.Add:7)\n  1336 (ai.onnx.Sqrt:6)\n  1337 (ai.onnx.Reciprocal:6)\n  1338 (ai.onnx.Mul:7)\n  1339 (ai.onnx.Mul:7)\n  1340 (ai.onnx.Sub:7)\n  1341 (ai.onnx.Mul:7)\n  1342 (ai.onnx.Add:7)\n  1343 (ai.onnx.MatMul:9)\n  1344 (ai.onnx.Add:7)\n  1345 (ai.onnx.Div:7)\n  1346 (ai.onnx.Erf:9)\n  1347 (ai.onnx.Add:7)\n  1348 (ai.onnx.Mul:7)\n  1349 (ai.onnx.Mul:7)\n  1350 (ai.onnx.MatMul:9)\n  1351 (ai.onnx.Add:7)\n  1352 (ai.onnx.Add:7)\n  1353 (ai.onnx.ReduceMean:11)\n  1354 (ai.onnx.Cast:9)\n  1355 (ai.onnx.Cast:9)\n  1356 (ai.onnx.Sub:7)\n  1357 (ai.onnx.Mul:7)\n  1358 (ai.onnx.ReduceMean:11)\n  1359 (ai.onnx.Cast:9)\n  1360 (ai.onnx.Add:7)\n  1361 (ai.onnx.Sqrt:6)\n  1362 (ai.onnx.Reciprocal:6)\n  1363 (ai.onnx.Mul:7)\n  1364 (ai.onnx.Mul:7)\n  1365 (ai.onnx.Sub:7)\n  1366 (ai.onnx.Mul:7)\n  1367 (ai.onnx.Add:7)\n  1368 (ai.onnx.MatMul:9)\n  1369 (ai.onnx.Add:7)\n  1370 (ai.onnx.Reshape:5)\n  1371 (ai.onnx.Transpose:1)\n  1372 (ai.onnx.MatMul:9)\n  1373 (ai.onnx.Add:7)\n  1374 (ai.onnx.Reshape:5)\n  1375 (ai.onnx.Transpose:1)\n  1376 (ai.onnx.MatMul:9)\n  1377 (ai.onnx.Add:7)\n  1378 (ai.onnx.Reshape:5)\n  1379 (ai.onnx.Transpose:1)\n  1380 (ai.onnx.MatMul:9)\n  1381 (ai.onnx.Mul:7)\n  1382 (ai.onnx.Add:7)\n  1383 (ai.onnx.Softmax:11)\n  1384 (ai.onnx.MatMul:9)\n  1385 (ai.onnx.Transpose:1)\n  1386 (ai.onnx.Reshape:5)\n  1387 (ai.onnx.MatMul:9)\n  1388 (ai.onnx.Add:7)\n  1389 (ai.onnx.Add:7)\n  1390 (ai.onnx.ReduceMean:11)\n  1391 (ai.onnx.Cast:9)\n  1392 (ai.onnx.Cast:9)\n  1393 (ai.onnx.Sub:7)\n  1394 (ai.onnx.Mul:7)\n  1395 (ai.onnx.ReduceMean:11)\n  1396 (ai.onnx.Cast:9)\n  1397 (ai.onnx.Add:7)\n  1398 (ai.onnx.Sqrt:6)\n  1399 (ai.onnx.Reciprocal:6)\n  1400 (ai.onnx.Mul:7)\n  1401 (ai.onnx.Mul:7)\n  1402 (ai.onnx.Sub:7)\n  1403 (ai.onnx.Mul:7)\n  1404 (ai.onnx.Add:7)\n  1405 (ai.onnx.MatMul:9)\n  1406 (ai.onnx.Add:7)\n  1407 (ai.onnx.Div:7)\n  1408 (ai.onnx.Erf:9)\n  1409 (ai.onnx.Add:7)\n  1410 (ai.onnx.Mul:7)\n  1411 (ai.onnx.Mul:7)\n  1412 (ai.onnx.MatMul:9)\n  1413 (ai.onnx.Add:7)\n  1414 (ai.onnx.Add:7)\n  1415 (ai.onnx.ReduceMean:11)\n  1416 (ai.onnx.Cast:9)\n  1417 (ai.onnx.Cast:9)\n  1418 (ai.onnx.Sub:7)\n  1419 (ai.onnx.Mul:7)\n  1420 (ai.onnx.ReduceMean:11)\n  1421 (ai.onnx.Cast:9)\n  1422 (ai.onnx.Add:7)\n  1423 (ai.onnx.Sqrt:6)\n  1424 (ai.onnx.Reciprocal:6)\n  1425 (ai.onnx.Mul:7)\n  1426 (ai.onnx.Mul:7)\n  1427 (ai.onnx.Sub:7)\n  1428 (ai.onnx.Mul:7)\n  1429 (ai.onnx.Add:7)\n  1430 (ai.onnx.MatMul:9)\n  1431 (ai.onnx.Add:7)\n  1432 (ai.onnx.Reshape:5)\n  1433 (ai.onnx.Transpose:1)\n  1434 (ai.onnx.MatMul:9)\n  1435 (ai.onnx.Add:7)\n  1436 (ai.onnx.Reshape:5)\n  1437 (ai.onnx.Transpose:1)\n  1438 (ai.onnx.MatMul:9)\n  1439 (ai.onnx.Add:7)\n  1440 (ai.onnx.Reshape:5)\n  1441 (ai.onnx.Transpose:1)\n  1442 (ai.onnx.MatMul:9)\n  1443 (ai.onnx.Mul:7)\n  1444 (ai.onnx.Add:7)\n  1445 (ai.onnx.Softmax:11)\n  1446 (ai.onnx.MatMul:9)\n  1447 (ai.onnx.Transpose:1)\n  1448 (ai.onnx.Reshape:5)\n  1449 (ai.onnx.MatMul:9)\n  1450 (ai.onnx.Add:7)\n  1451 (ai.onnx.Add:7)\n  1452 (ai.onnx.ReduceMean:11)\n  1453 (ai.onnx.Cast:9)\n  1454 (ai.onnx.Cast:9)\n  1455 (ai.onnx.Sub:7)\n  1456 (ai.onnx.Mul:7)\n  1457 (ai.onnx.ReduceMean:11)\n  1458 (ai.onnx.Cast:9)\n  1459 (ai.onnx.Add:7)\n  1460 (ai.onnx.Sqrt:6)\n  1461 (ai.onnx.Reciprocal:6)\n  1462 (ai.onnx.Mul:7)\n  1463 (ai.onnx.Mul:7)\n  1464 (ai.onnx.Sub:7)\n  1465 (ai.onnx.Mul:7)\n  1466 (ai.onnx.Add:7)\n  1467 (ai.onnx.MatMul:9)\n  1468 (ai.onnx.Add:7)\n  1469 (ai.onnx.Div:7)\n  1470 (ai.onnx.Erf:9)\n  1471 (ai.onnx.Add:7)\n  1472 (ai.onnx.Mul:7)\n  1473 (ai.onnx.Mul:7)\n  1474 (ai.onnx.MatMul:9)\n  1475 (ai.onnx.Add:7)\n  1476 (ai.onnx.Add:7)\n  1477 (ai.onnx.ReduceMean:11)\n  1478 (ai.onnx.Cast:9)\n  1479 (ai.onnx.Cast:9)\n  1480 (ai.onnx.Sub:7)\n  1481 (ai.onnx.Mul:7)\n  1482 (ai.onnx.ReduceMean:11)\n  1483 (ai.onnx.Cast:9)\n  1484 (ai.onnx.Add:7)\n  1485 (ai.onnx.Sqrt:6)\n  1486 (ai.onnx.Reciprocal:6)\n  1487 (ai.onnx.Mul:7)\n  1488 (ai.onnx.Mul:7)\n  1489 (ai.onnx.Sub:7)\n  1490 (ai.onnx.Mul:7)\n  1491 (ai.onnx.Add:7)\n  1492 (ai.onnx.MatMul:9)\n  1493 (ai.onnx.Add:7)\n  1494 (ai.onnx.Reshape:5)\n  1495 (ai.onnx.Transpose:1)\n  1496 (ai.onnx.MatMul:9)\n  1497 (ai.onnx.Add:7)\n  1498 (ai.onnx.Reshape:5)\n  1499 (ai.onnx.Transpose:1)\n  1500 (ai.onnx.MatMul:9)\n  1501 (ai.onnx.Add:7)\n  1502 (ai.onnx.Reshape:5)\n  1503 (ai.onnx.Transpose:1)\n  1504 (ai.onnx.MatMul:9)\n  1505 (ai.onnx.Mul:7)\n  1506 (ai.onnx.Add:7)\n  1507 (ai.onnx.Softmax:11)\n  1508 (ai.onnx.MatMul:9)\n  1509 (ai.onnx.Transpose:1)\n  1510 (ai.onnx.Reshape:5)\n  1511 (ai.onnx.MatMul:9)\n  1512 (ai.onnx.Add:7)\n  1513 (ai.onnx.Add:7)\n  1514 (ai.onnx.ReduceMean:11)\n  1515 (ai.onnx.Cast:9)\n  1516 (ai.onnx.Cast:9)\n  1517 (ai.onnx.Sub:7)\n  1518 (ai.onnx.Mul:7)\n  1519 (ai.onnx.ReduceMean:11)\n  1520 (ai.onnx.Cast:9)\n  1521 (ai.onnx.Add:7)\n  1522 (ai.onnx.Sqrt:6)\n  1523 (ai.onnx.Reciprocal:6)\n  1524 (ai.onnx.Mul:7)\n  1525 (ai.onnx.Mul:7)\n  1526 (ai.onnx.Sub:7)\n  1527 (ai.onnx.Mul:7)\n  1528 (ai.onnx.Add:7)\n  1529 (ai.onnx.MatMul:9)\n  1530 (ai.onnx.Add:7)\n  1531 (ai.onnx.Div:7)\n  1532 (ai.onnx.Erf:9)\n  1533 (ai.onnx.Add:7)\n  1534 (ai.onnx.Mul:7)\n  1535 (ai.onnx.Mul:7)\n  1536 (ai.onnx.MatMul:9)\n  1537 (ai.onnx.Add:7)\n  1538 (ai.onnx.Add:7)\n  1539 (ai.onnx.ReduceMean:11)\n  1540 (ai.onnx.Cast:9)\n  1541 (ai.onnx.Cast:9)\n  1542 (ai.onnx.Sub:7)\n  1543 (ai.onnx.Mul:7)\n  1544 (ai.onnx.ReduceMean:11)\n  1545 (ai.onnx.Cast:9)\n  1546 (ai.onnx.Add:7)\n  1547 (ai.onnx.Sqrt:6)\n  1548 (ai.onnx.Reciprocal:6)\n  1549 (ai.onnx.Mul:7)\n  1550 (ai.onnx.Mul:7)\n  1551 (ai.onnx.Sub:7)\n  1552 (ai.onnx.Mul:7)\n  1553 (ai.onnx.Add:7)\n  1554 (ai.onnx.MatMul:9)\n  1555 (ai.onnx.Add:7)\n  1556 (ai.onnx.Reshape:5)\n  1557 (ai.onnx.Transpose:1)\n  1558 (ai.onnx.MatMul:9)\n  1559 (ai.onnx.Add:7)\n  1560 (ai.onnx.Reshape:5)\n  1561 (ai.onnx.Transpose:1)\n  1562 (ai.onnx.MatMul:9)\n  1563 (ai.onnx.Add:7)\n  1564 (ai.onnx.Reshape:5)\n  1565 (ai.onnx.Transpose:1)\n  1566 (ai.onnx.MatMul:9)\n  1567 (ai.onnx.Mul:7)\n  1568 (ai.onnx.Add:7)\n  1569 (ai.onnx.Softmax:11)\n  1570 (ai.onnx.MatMul:9)\n  1571 (ai.onnx.Transpose:1)\n  1572 (ai.onnx.Reshape:5)\n  1573 (ai.onnx.MatMul:9)\n  1574 (ai.onnx.Add:7)\n  1575 (ai.onnx.Add:7)\n  1576 (ai.onnx.ReduceMean:11)\n  1577 (ai.onnx.Cast:9)\n  1578 (ai.onnx.Cast:9)\n  1579 (ai.onnx.Sub:7)\n  1580 (ai.onnx.Mul:7)\n  1581 (ai.onnx.ReduceMean:11)\n  1582 (ai.onnx.Cast:9)\n  1583 (ai.onnx.Add:7)\n  1584 (ai.onnx.Sqrt:6)\n  1585 (ai.onnx.Reciprocal:6)\n  1586 (ai.onnx.Mul:7)\n  1587 (ai.onnx.Mul:7)\n  1588 (ai.onnx.Sub:7)\n  1589 (ai.onnx.Mul:7)\n  1590 (ai.onnx.Add:7)\n  1591 (ai.onnx.MatMul:9)\n  1592 (ai.onnx.Add:7)\n  1593 (ai.onnx.Div:7)\n  1594 (ai.onnx.Erf:9)\n  1595 (ai.onnx.Add:7)\n  1596 (ai.onnx.Mul:7)\n  1597 (ai.onnx.Mul:7)\n  1598 (ai.onnx.MatMul:9)\n  1599 (ai.onnx.Add:7)\n  1600 (ai.onnx.Add:7)\n  1601 (ai.onnx.ReduceMean:11)\n  1602 (ai.onnx.Cast:9)\n  1603 (ai.onnx.Cast:9)\n  1604 (ai.onnx.Sub:7)\n  1605 (ai.onnx.Mul:7)\n  1606 (ai.onnx.ReduceMean:11)\n  1607 (ai.onnx.Cast:9)\n  1608 (ai.onnx.Add:7)\n  1609 (ai.onnx.Sqrt:6)\n  1610 (ai.onnx.Reciprocal:6)\n  1611 (ai.onnx.Mul:7)\n  1612 (ai.onnx.Mul:7)\n  1613 (ai.onnx.Sub:7)\n  1614 (ai.onnx.Mul:7)\n  1615 (ai.onnx.Add:7)\n  1616 (ai.onnx.MatMul:9)\n  1617 (ai.onnx.Add:7)\n  1618 (ai.onnx.Reshape:5)\n  1619 (ai.onnx.Transpose:1)\n  1620 (ai.onnx.MatMul:9)\n  1621 (ai.onnx.Add:7)\n  1622 (ai.onnx.Reshape:5)\n  1623 (ai.onnx.Transpose:1)\n  1624 (ai.onnx.MatMul:9)\n  1625 (ai.onnx.Add:7)\n  1626 (ai.onnx.Reshape:5)\n  1627 (ai.onnx.Transpose:1)\n  1628 (ai.onnx.MatMul:9)\n  1629 (ai.onnx.Mul:7)\n  1630 (ai.onnx.Add:7)\n  1631 (ai.onnx.Softmax:11)\n  1632 (ai.onnx.MatMul:9)\n  1633 (ai.onnx.Transpose:1)\n  1634 (ai.onnx.Reshape:5)\n  1635 (ai.onnx.MatMul:9)\n  1636 (ai.onnx.Add:7)\n  1637 (ai.onnx.Add:7)\n  1638 (ai.onnx.ReduceMean:11)\n  1639 (ai.onnx.Cast:9)\n  1640 (ai.onnx.Cast:9)\n  1641 (ai.onnx.Sub:7)\n  1642 (ai.onnx.Mul:7)\n  1643 (ai.onnx.ReduceMean:11)\n  1644 (ai.onnx.Cast:9)\n  1645 (ai.onnx.Add:7)\n  1646 (ai.onnx.Sqrt:6)\n  1647 (ai.onnx.Reciprocal:6)\n  1648 (ai.onnx.Mul:7)\n  1649 (ai.onnx.Mul:7)\n  1650 (ai.onnx.Sub:7)\n  1651 (ai.onnx.Mul:7)\n  1652 (ai.onnx.Add:7)\n  1653 (ai.onnx.MatMul:9)\n  1654 (ai.onnx.Add:7)\n  1655 (ai.onnx.Div:7)\n  1656 (ai.onnx.Erf:9)\n  1657 (ai.onnx.Add:7)\n  1658 (ai.onnx.Mul:7)\n  1659 (ai.onnx.Mul:7)\n  1660 (ai.onnx.MatMul:9)\n  1661 (ai.onnx.Add:7)\n  1662 (ai.onnx.Add:7)\n  1663 (ai.onnx.ReduceMean:11)\n  1664 (ai.onnx.Cast:9)\n  1665 (ai.onnx.Cast:9)\n  1666 (ai.onnx.Sub:7)\n  1667 (ai.onnx.Mul:7)\n  1668 (ai.onnx.ReduceMean:11)\n  1669 (ai.onnx.Cast:9)\n  1670 (ai.onnx.Add:7)\n  1671 (ai.onnx.Sqrt:6)\n  1672 (ai.onnx.Reciprocal:6)\n  1673 (ai.onnx.Mul:7)\n  1674 (ai.onnx.Mul:7)\n  1675 (ai.onnx.Sub:7)\n  1676 (ai.onnx.Mul:7)\n  1677 (ai.onnx.Add:7)\n  1678 (ai.onnx.MatMul:9)\n  1679 (ai.onnx.Add:7)\n  1680 (ai.onnx.Reshape:5)\n  1681 (ai.onnx.Transpose:1)\n  1682 (ai.onnx.MatMul:9)\n  1683 (ai.onnx.Add:7)\n  1684 (ai.onnx.Reshape:5)\n  1685 (ai.onnx.Transpose:1)\n  1686 (ai.onnx.MatMul:9)\n  1687 (ai.onnx.Add:7)\n  1688 (ai.onnx.Reshape:5)\n  1689 (ai.onnx.Transpose:1)\n  1690 (ai.onnx.MatMul:9)\n  1691 (ai.onnx.Mul:7)\n  1692 (ai.onnx.Add:7)\n  1693 (ai.onnx.Softmax:11)\n  1694 (ai.onnx.MatMul:9)\n  1695 (ai.onnx.Transpose:1)\n  1696 (ai.onnx.Reshape:5)\n  1697 (ai.onnx.MatMul:9)\n  1698 (ai.onnx.Add:7)\n  1699 (ai.onnx.Add:7)\n  1700 (ai.onnx.ReduceMean:11)\n  1701 (ai.onnx.Cast:9)\n  1702 (ai.onnx.Cast:9)\n  1703 (ai.onnx.Sub:7)\n  1704 (ai.onnx.Mul:7)\n  1705 (ai.onnx.ReduceMean:11)\n  1706 (ai.onnx.Cast:9)\n  1707 (ai.onnx.Add:7)\n  1708 (ai.onnx.Sqrt:6)\n  1709 (ai.onnx.Reciprocal:6)\n  1710 (ai.onnx.Mul:7)\n  1711 (ai.onnx.Mul:7)\n  1712 (ai.onnx.Sub:7)\n  1713 (ai.onnx.Mul:7)\n  1714 (ai.onnx.Add:7)\n  1715 (ai.onnx.MatMul:9)\n  1716 (ai.onnx.Add:7)\n  1717 (ai.onnx.Div:7)\n  1718 (ai.onnx.Erf:9)\n  1719 (ai.onnx.Add:7)\n  1720 (ai.onnx.Mul:7)\n  1721 (ai.onnx.Mul:7)\n  1722 (ai.onnx.MatMul:9)\n  1723 (ai.onnx.Add:7)\n  1724 (ai.onnx.Add:7)\n  1725 (ai.onnx.ReduceMean:11)\n  1726 (ai.onnx.Cast:9)\n  1727 (ai.onnx.Cast:9)\n  1728 (ai.onnx.Sub:7)\n  1729 (ai.onnx.Mul:7)\n  1730 (ai.onnx.ReduceMean:11)\n  1731 (ai.onnx.Cast:9)\n  1732 (ai.onnx.Add:7)\n  1733 (ai.onnx.Sqrt:6)\n  1734 (ai.onnx.Reciprocal:6)\n  1735 (ai.onnx.Mul:7)\n  1736 (ai.onnx.Mul:7)\n  1737 (ai.onnx.Sub:7)\n  1738 (ai.onnx.Mul:7)\n  1739 (ai.onnx.Add:7)\n  1740 (ai.onnx.Reshape:5)\n  1741 (ai.onnx.Slice:11)\n  1742 (ai.onnx.Reshape:5)\n  1743 (ai.onnx.MatMul:9)\n  1744 (ai.onnx.Add:7)\n  1745 (ai.onnx.Tanh:6)\n"
     ]
    }
   ],
   "source": [
    "run(builder, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reload_ns) + len(reload_qt_ns) + len(rest_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mk.graph.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input: \"reload/bert/encoder/mul:0\"\n",
       "output: \"reload/bert/encoder/layer_0/attention/self/ExpandDims:0\"\n",
       "name: \"reload/bert/encoder/layer_0/attention/self/ExpandDims\"\n",
       "op_type: \"Unsqueeze\"\n",
       "attribute {\n",
       "  name: \"axes\"\n",
       "  ints: 1\n",
       "  type: INTS\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk.graph.node[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = popart.Builder(m.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = popart.SessionOptions()\n",
    "opts.virtualGraphMode = popart.VirtualGraphMode.Manual\n",
    "opts.enablePipelining = True\n",
    "partials_type = \"half\"\n",
    "opts.partialsTypeMatMuls = partials_type\n",
    "opts.convolutionOptions = {'partialsType': partials_type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorDict/StandardKvParser_4:0', 'TensorDict/StandardKvParser_1:0', 'TensorDict/StandardKvParser_6:0', 'TensorDict/StandardKvParser_8:0']\n",
      "[[1, 512], [1, 64], [1, 512], [1, 64]]\n",
      "['INT32', 'INT32', 'INT32', 'INT32']\n"
     ]
    },
    {
     "ename": "popart_exception",
     "evalue": "For pipelining, depth (batchesPerStep) must equal at least the number of pipeline stages (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mpopart_exception\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-7f402b991a23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-0b592e380a0f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(builder, opts, batch_size, batch_per_step, n_sample)\u001b[0m\n\u001b[1;32m     35\u001b[0m     session = popart.InferenceSession(builder.getModelProto(), dataflow, device, \n\u001b[1;32m     36\u001b[0m                                     \u001b[0minputShapeInfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputShapeInfo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                                     userOptions=opts)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepareDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/scratch001/custeng-cn-scratch/yongxiy/sdk/poplar_sdk-ubuntu_18_04-2.1.0-EA.1+539-af8454999a/popart-ubuntu_18_04-2.1.0+124588-d0630ea3a6/python/popart/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fnModel, dataFlow, deviceInfo, inputShapeInfo, patterns, userOptions)\u001b[0m\n\u001b[1;32m    137\u001b[0m         super(InferenceSession,\n\u001b[1;32m    138\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeviceInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputShapeInfo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                              userOptions, patterns)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFlow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataFlow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mpopart_exception\u001b[0m: For pipelining, depth (batchesPerStep) must equal at least the number of pipeline stages (2)"
     ]
    }
   ],
   "source": [
    "run(builder=builder, opts=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_names = [\"reload/bert/embeddings\", \"reload/bert/encoder/layer_0/\", \"reload/bert/encoder/layer_1/\", \"reload/bert/encoder/layer_2/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reload/bert/embeddings/Reshape_1\n",
      "reload/bert/encoder/Shape\n",
      "reload/bert/encoder/Shape__459\n",
      "reload/bert/encoder/strided_slice\n",
      "reload/bert/encoder/ones/packed_Concat__467\n",
      "reload/bert/encoder/ones__468\n",
      "reload/bert/encoder/ones\n",
      "reload/bert/encoder/Reshape/shape_Concat__472\n",
      "reload/bert/encoder/Reshape__734\n",
      "reload/bert/embeddings/ExpandDims\n",
      "reload/bert/embeddings/embedding_lookup\n",
      "reload/bert/embeddings/Shape\n",
      "reload/bert/embeddings/Shape__473\n",
      "reload/bert/embeddings/strided_slice\n",
      "reload/bert/embeddings/Reshape/shape_Concat__481\n",
      "reload/bert/embeddings/Reshape__482\n",
      "reload/bert/embeddings/Reshape\n",
      "reload/bert/embeddings/Shape_1\n",
      "reload/bert/embeddings/Shape_1__483\n",
      "reload/bert/embeddings/strided_slice_1\n",
      "reload/bert/embeddings/Reshape_2/shape_Concat__491\n",
      "reload/bert/embeddings/Reshape_2__492\n",
      "reload/bert/encoder/Reshape\n",
      "reload/bert/encoder/mul\n",
      "reload/bert/encoder/layer_0/attention/self/ExpandDims\n",
      "reload/bert/encoder/layer_9/attention/self/sub\n",
      "reload/bert/encoder/layer_9/attention/self/mul_1\n",
      "reload/bert/embeddings/one_hot\n",
      "reload/bert/embeddings/MatMul\n",
      "reload/bert/embeddings/Reshape_2\n",
      "reload/bert/embeddings/add\n",
      "reload/bert/embeddings/add_1\n",
      "reload/bert/embeddings/LayerNorm/moments/mean\n",
      "reload/bert/embeddings/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/embeddings/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/embeddings/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/embeddings/LayerNorm/moments/SquaredDifference__493\n",
      "reload/bert/embeddings/LayerNorm/moments/variance\n",
      "reload/bert/embeddings/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/embeddings/LayerNorm/batchnorm/add\n",
      "reload/bert/embeddings/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/embeddings/LayerNorm/batchnorm/Rsqrt__496\n",
      "reload/bert/embeddings/LayerNorm/batchnorm/mul\n",
      "reload/bert/embeddings/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/embeddings/LayerNorm/batchnorm/sub\n",
      "reload/bert/embeddings/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/embeddings/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/Shape_2\n",
      "reload/bert/encoder/Shape_2__498\n",
      "reload/bert/encoder/strided_slice_2\n",
      "reload/bert/encoder/strided_slice_2__502\n",
      "reload/bert/encoder/layer_9/attention/self/Reshape_1/shape_Unsqueeze__511\n",
      "reload/bert/encoder/layer_6/attention/self/Reshape/shape_Concat__574\n",
      "reload/bert/encoder/layer_7/attention/self/Reshape__843\n",
      "reload/bert/encoder/Reshape_13/shape_Concat__722\n",
      "reload/bert/encoder/Reshape_13__922\n",
      "reload/bert/encoder/layer_7/attention/self/mul_2\n",
      "reload/bert/encoder/layer_6/attention/self/Reshape_3/shape_Unsqueeze__557\n",
      "reload/bert/encoder/layer_9/attention/self/Reshape_3/shape_Concat__505\n",
      "reload/bert/encoder/layer_2/attention/self/Reshape_3__767\n",
      "reload/bert/encoder/Reshape_1\n",
      "reload/bert/encoder/layer_0/attention/self/value/MatMul\n",
      "reload/bert/encoder/layer_0/attention/self/value/BiasAdd\n",
      "reload/bert/encoder/layer_0/attention/self/Reshape_2\n",
      "reload/bert/encoder/layer_0/attention/self/transpose_2\n",
      "reload/bert/encoder/layer_0/attention/self/query/MatMul\n",
      "reload/bert/encoder/layer_0/attention/self/query/BiasAdd\n",
      "reload/bert/encoder/layer_0/attention/self/Reshape\n",
      "reload/bert/encoder/layer_0/attention/self/transpose\n",
      "reload/bert/encoder/layer_0/attention/self/key/MatMul\n",
      "reload/bert/encoder/layer_0/attention/self/key/BiasAdd\n",
      "reload/bert/encoder/layer_0/attention/self/Reshape_1\n",
      "reload/bert/encoder/layer_0/attention/self/MatMul__727\n",
      "reload/bert/encoder/layer_0/attention/self/MatMul\n",
      "reload/bert/encoder/layer_0/attention/self/Mul\n",
      "reload/bert/encoder/layer_0/attention/self/add\n",
      "reload/bert/encoder/layer_0/attention/self/Softmax\n",
      "reload/bert/encoder/layer_0/attention/self/MatMul_1\n",
      "reload/bert/encoder/layer_0/attention/self/transpose_3\n",
      "reload/bert/encoder/layer_0/attention/self/Reshape_3\n",
      "reload/bert/encoder/layer_0/attention/output/dense/MatMul\n",
      "reload/bert/encoder/layer_0/attention/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_0/attention/output/add\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/moments/SquaredDifference__736\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/Rsqrt__739\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_0/attention/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_0/intermediate/dense/MatMul\n",
      "reload/bert/encoder/layer_0/intermediate/dense/BiasAdd\n",
      "reload/bert/encoder/layer_0/intermediate/dense/truediv\n",
      "reload/bert/encoder/layer_0/intermediate/dense/Erf\n",
      "reload/bert/encoder/layer_0/intermediate/dense/add\n",
      "reload/bert/encoder/layer_0/intermediate/dense/mul\n",
      "reload/bert/encoder/layer_0/intermediate/dense/mul_1\n",
      "reload/bert/encoder/layer_0/output/dense/MatMul\n",
      "reload/bert/encoder/layer_0/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_0/output/add\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/moments/SquaredDifference__741\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/batchnorm/Rsqrt__744\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_0/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_1/attention/self/value/MatMul\n",
      "reload/bert/encoder/layer_1/attention/self/value/BiasAdd\n",
      "reload/bert/encoder/layer_1/attention/self/Reshape_2\n",
      "reload/bert/encoder/layer_1/attention/self/transpose_2\n",
      "reload/bert/encoder/layer_1/attention/self/query/MatMul\n",
      "reload/bert/encoder/layer_1/attention/self/query/BiasAdd\n",
      "reload/bert/encoder/layer_1/attention/self/Reshape\n",
      "reload/bert/encoder/layer_1/attention/self/transpose\n",
      "reload/bert/encoder/layer_1/attention/self/key/MatMul\n",
      "reload/bert/encoder/layer_1/attention/self/key/BiasAdd\n",
      "reload/bert/encoder/layer_1/attention/self/Reshape_1\n",
      "reload/bert/encoder/layer_1/attention/self/MatMul__749\n",
      "reload/bert/encoder/layer_1/attention/self/MatMul\n",
      "reload/bert/encoder/layer_1/attention/self/Mul\n",
      "reload/bert/encoder/layer_1/attention/self/add\n",
      "reload/bert/encoder/layer_1/attention/self/Softmax\n",
      "reload/bert/encoder/layer_1/attention/self/MatMul_1\n",
      "reload/bert/encoder/layer_1/attention/self/transpose_3\n",
      "reload/bert/encoder/layer_1/attention/self/Reshape_3\n",
      "reload/bert/encoder/layer_1/attention/output/dense/MatMul\n",
      "reload/bert/encoder/layer_1/attention/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_1/attention/output/add\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/moments/SquaredDifference__752\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/Rsqrt__755\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_1/attention/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_1/intermediate/dense/MatMul\n",
      "reload/bert/encoder/layer_1/intermediate/dense/BiasAdd\n",
      "reload/bert/encoder/layer_1/intermediate/dense/truediv\n",
      "reload/bert/encoder/layer_1/intermediate/dense/Erf\n",
      "reload/bert/encoder/layer_1/intermediate/dense/add\n",
      "reload/bert/encoder/layer_1/intermediate/dense/mul\n",
      "reload/bert/encoder/layer_1/intermediate/dense/mul_1\n",
      "reload/bert/encoder/layer_1/output/dense/MatMul\n",
      "reload/bert/encoder/layer_1/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_1/output/add\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/moments/SquaredDifference__757\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/batchnorm/Rsqrt__760\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_1/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_2/attention/self/value/MatMul\n",
      "reload/bert/encoder/layer_2/attention/self/value/BiasAdd\n",
      "reload/bert/encoder/layer_2/attention/self/Reshape_2\n",
      "reload/bert/encoder/layer_2/attention/self/transpose_2\n",
      "reload/bert/encoder/layer_2/attention/self/query/MatMul\n",
      "reload/bert/encoder/layer_2/attention/self/query/BiasAdd\n",
      "reload/bert/encoder/layer_2/attention/self/Reshape\n",
      "reload/bert/encoder/layer_2/attention/self/transpose\n",
      "reload/bert/encoder/layer_2/attention/self/key/MatMul\n",
      "reload/bert/encoder/layer_2/attention/self/key/BiasAdd\n",
      "reload/bert/encoder/layer_2/attention/self/Reshape_1\n",
      "reload/bert/encoder/layer_2/attention/self/MatMul__765\n",
      "reload/bert/encoder/layer_2/attention/self/MatMul\n",
      "reload/bert/encoder/layer_2/attention/self/Mul\n",
      "reload/bert/encoder/layer_2/attention/self/add\n",
      "reload/bert/encoder/layer_2/attention/self/Softmax\n",
      "reload/bert/encoder/layer_2/attention/self/MatMul_1\n",
      "reload/bert/encoder/layer_2/attention/self/transpose_3\n",
      "reload/bert/encoder/layer_2/attention/self/Reshape_3\n",
      "reload/bert/encoder/layer_2/attention/output/dense/MatMul\n",
      "reload/bert/encoder/layer_2/attention/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_2/attention/output/add\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/moments/SquaredDifference__768\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/Rsqrt__771\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_2/attention/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_2/intermediate/dense/MatMul\n",
      "reload/bert/encoder/layer_2/intermediate/dense/BiasAdd\n",
      "reload/bert/encoder/layer_2/intermediate/dense/truediv\n",
      "reload/bert/encoder/layer_2/intermediate/dense/Erf\n",
      "reload/bert/encoder/layer_2/intermediate/dense/add\n",
      "reload/bert/encoder/layer_2/intermediate/dense/mul\n",
      "reload/bert/encoder/layer_2/intermediate/dense/mul_1\n",
      "reload/bert/encoder/layer_2/output/dense/MatMul\n",
      "reload/bert/encoder/layer_2/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_2/output/add\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/moments/SquaredDifference__773\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/batchnorm/Rsqrt__776\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_2/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_3/attention/self/value/MatMul\n",
      "reload/bert/encoder/layer_3/attention/self/value/BiasAdd\n",
      "reload/bert/encoder/layer_3/attention/self/Reshape_2\n",
      "reload/bert/encoder/layer_3/attention/self/transpose_2\n",
      "reload/bert/encoder/layer_3/attention/self/query/MatMul\n",
      "reload/bert/encoder/layer_3/attention/self/query/BiasAdd\n",
      "reload/bert/encoder/layer_3/attention/self/Reshape\n",
      "reload/bert/encoder/layer_3/attention/self/transpose\n",
      "reload/bert/encoder/layer_3/attention/self/key/MatMul\n",
      "reload/bert/encoder/layer_3/attention/self/key/BiasAdd\n",
      "reload/bert/encoder/layer_3/attention/self/Reshape_1\n",
      "reload/bert/encoder/layer_3/attention/self/MatMul__781\n",
      "reload/bert/encoder/layer_3/attention/self/MatMul\n",
      "reload/bert/encoder/layer_3/attention/self/Mul\n",
      "reload/bert/encoder/layer_3/attention/self/add\n",
      "reload/bert/encoder/layer_3/attention/self/Softmax\n",
      "reload/bert/encoder/layer_3/attention/self/MatMul_1\n",
      "reload/bert/encoder/layer_3/attention/self/transpose_3\n",
      "reload/bert/encoder/layer_3/attention/self/Reshape_3\n",
      "reload/bert/encoder/layer_3/attention/output/dense/MatMul\n",
      "reload/bert/encoder/layer_3/attention/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_3/attention/output/add\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/moments/SquaredDifference__784\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/Rsqrt__787\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_3/attention/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_3/intermediate/dense/MatMul\n",
      "reload/bert/encoder/layer_3/intermediate/dense/BiasAdd\n",
      "reload/bert/encoder/layer_3/intermediate/dense/truediv\n",
      "reload/bert/encoder/layer_3/intermediate/dense/Erf\n",
      "reload/bert/encoder/layer_3/intermediate/dense/add\n",
      "reload/bert/encoder/layer_3/intermediate/dense/mul\n",
      "reload/bert/encoder/layer_3/intermediate/dense/mul_1\n",
      "reload/bert/encoder/layer_3/output/dense/MatMul\n",
      "reload/bert/encoder/layer_3/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_3/output/add\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/moments/SquaredDifference__789\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/batchnorm/Rsqrt__792\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_3/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_4/attention/self/value/MatMul\n",
      "reload/bert/encoder/layer_4/attention/self/value/BiasAdd\n",
      "reload/bert/encoder/layer_4/attention/self/Reshape_2\n",
      "reload/bert/encoder/layer_4/attention/self/transpose_2\n",
      "reload/bert/encoder/layer_4/attention/self/query/MatMul\n",
      "reload/bert/encoder/layer_4/attention/self/query/BiasAdd\n",
      "reload/bert/encoder/layer_4/attention/self/Reshape\n",
      "reload/bert/encoder/layer_4/attention/self/transpose\n",
      "reload/bert/encoder/layer_4/attention/self/key/MatMul\n",
      "reload/bert/encoder/layer_4/attention/self/key/BiasAdd\n",
      "reload/bert/encoder/layer_4/attention/self/Reshape_1\n",
      "reload/bert/encoder/layer_4/attention/self/MatMul__797\n",
      "reload/bert/encoder/layer_4/attention/self/MatMul\n",
      "reload/bert/encoder/layer_4/attention/self/Mul\n",
      "reload/bert/encoder/layer_4/attention/self/add\n",
      "reload/bert/encoder/layer_4/attention/self/Softmax\n",
      "reload/bert/encoder/layer_4/attention/self/MatMul_1\n",
      "reload/bert/encoder/layer_4/attention/self/transpose_3\n",
      "reload/bert/encoder/layer_4/attention/self/Reshape_3\n",
      "reload/bert/encoder/layer_4/attention/output/dense/MatMul\n",
      "reload/bert/encoder/layer_4/attention/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_4/attention/output/add\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/moments/SquaredDifference__800\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/Rsqrt__803\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_4/attention/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_4/intermediate/dense/MatMul\n",
      "reload/bert/encoder/layer_4/intermediate/dense/BiasAdd\n",
      "reload/bert/encoder/layer_4/intermediate/dense/truediv\n",
      "reload/bert/encoder/layer_4/intermediate/dense/Erf\n",
      "reload/bert/encoder/layer_4/intermediate/dense/add\n",
      "reload/bert/encoder/layer_4/intermediate/dense/mul\n",
      "reload/bert/encoder/layer_4/intermediate/dense/mul_1\n",
      "reload/bert/encoder/layer_4/output/dense/MatMul\n",
      "reload/bert/encoder/layer_4/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_4/output/add\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/moments/SquaredDifference__805\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/batchnorm/Rsqrt__808\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_4/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_5/attention/self/value/MatMul\n",
      "reload/bert/encoder/layer_5/attention/self/value/BiasAdd\n",
      "reload/bert/encoder/layer_5/attention/self/Reshape_2\n",
      "reload/bert/encoder/layer_5/attention/self/transpose_2\n",
      "reload/bert/encoder/layer_5/attention/self/query/MatMul\n",
      "reload/bert/encoder/layer_5/attention/self/query/BiasAdd\n",
      "reload/bert/encoder/layer_5/attention/self/Reshape\n",
      "reload/bert/encoder/layer_5/attention/self/transpose\n",
      "reload/bert/encoder/layer_5/attention/self/key/MatMul\n",
      "reload/bert/encoder/layer_5/attention/self/key/BiasAdd\n",
      "reload/bert/encoder/layer_5/attention/self/Reshape_1\n",
      "reload/bert/encoder/layer_5/attention/self/MatMul__813\n",
      "reload/bert/encoder/layer_5/attention/self/MatMul\n",
      "reload/bert/encoder/layer_5/attention/self/Mul\n",
      "reload/bert/encoder/layer_5/attention/self/add\n",
      "reload/bert/encoder/layer_5/attention/self/Softmax\n",
      "reload/bert/encoder/layer_5/attention/self/MatMul_1\n",
      "reload/bert/encoder/layer_5/attention/self/transpose_3\n",
      "reload/bert/encoder/layer_5/attention/self/Reshape_3\n",
      "reload/bert/encoder/layer_5/attention/output/dense/MatMul\n",
      "reload/bert/encoder/layer_5/attention/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_5/attention/output/add\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/moments/SquaredDifference__816\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/Rsqrt__819\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_5/attention/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_5/intermediate/dense/MatMul\n",
      "reload/bert/encoder/layer_5/intermediate/dense/BiasAdd\n",
      "reload/bert/encoder/layer_5/intermediate/dense/truediv\n",
      "reload/bert/encoder/layer_5/intermediate/dense/Erf\n",
      "reload/bert/encoder/layer_5/intermediate/dense/add\n",
      "reload/bert/encoder/layer_5/intermediate/dense/mul\n",
      "reload/bert/encoder/layer_5/intermediate/dense/mul_1\n",
      "reload/bert/encoder/layer_5/output/dense/MatMul\n",
      "reload/bert/encoder/layer_5/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_5/output/add\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/moments/SquaredDifference__821\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/batchnorm/Rsqrt__824\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_5/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_6/attention/self/value/MatMul\n",
      "reload/bert/encoder/layer_6/attention/self/value/BiasAdd\n",
      "reload/bert/encoder/layer_6/attention/self/Reshape_2\n",
      "reload/bert/encoder/layer_6/attention/self/transpose_2\n",
      "reload/bert/encoder/layer_6/attention/self/query/MatMul\n",
      "reload/bert/encoder/layer_6/attention/self/query/BiasAdd\n",
      "reload/bert/encoder/layer_6/attention/self/Reshape\n",
      "reload/bert/encoder/layer_6/attention/self/transpose\n",
      "reload/bert/encoder/layer_6/attention/self/key/MatMul\n",
      "reload/bert/encoder/layer_6/attention/self/key/BiasAdd\n",
      "reload/bert/encoder/layer_6/attention/self/Reshape_1\n",
      "reload/bert/encoder/layer_6/attention/self/MatMul__829\n",
      "reload/bert/encoder/layer_6/attention/self/MatMul\n",
      "reload/bert/encoder/layer_6/attention/self/Mul\n",
      "reload/bert/encoder/layer_6/attention/self/add\n",
      "reload/bert/encoder/layer_6/attention/self/Softmax\n",
      "reload/bert/encoder/layer_6/attention/self/MatMul_1\n",
      "reload/bert/encoder/layer_6/attention/self/transpose_3\n",
      "reload/bert/encoder/layer_6/attention/self/Reshape_3\n",
      "reload/bert/encoder/layer_6/attention/output/dense/MatMul\n",
      "reload/bert/encoder/layer_6/attention/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_6/attention/output/add\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/moments/SquaredDifference__832\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/Rsqrt__835\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_6/attention/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_6/intermediate/dense/MatMul\n",
      "reload/bert/encoder/layer_6/intermediate/dense/BiasAdd\n",
      "reload/bert/encoder/layer_6/intermediate/dense/truediv\n",
      "reload/bert/encoder/layer_6/intermediate/dense/Erf\n",
      "reload/bert/encoder/layer_6/intermediate/dense/add\n",
      "reload/bert/encoder/layer_6/intermediate/dense/mul\n",
      "reload/bert/encoder/layer_6/intermediate/dense/mul_1\n",
      "reload/bert/encoder/layer_6/output/dense/MatMul\n",
      "reload/bert/encoder/layer_6/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_6/output/add\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/moments/SquaredDifference__837\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/batchnorm/Rsqrt__840\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_6/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_7/attention/self/value/MatMul\n",
      "reload/bert/encoder/layer_7/attention/self/value/BiasAdd\n",
      "reload/bert/encoder/layer_7/attention/self/Reshape_2\n",
      "reload/bert/encoder/layer_7/attention/self/transpose_2\n",
      "reload/bert/encoder/layer_7/attention/self/query/MatMul\n",
      "reload/bert/encoder/layer_7/attention/self/query/BiasAdd\n",
      "reload/bert/encoder/layer_7/attention/self/Reshape\n",
      "reload/bert/encoder/layer_7/attention/self/transpose\n",
      "reload/bert/encoder/layer_7/attention/self/key/MatMul\n",
      "reload/bert/encoder/layer_7/attention/self/key/BiasAdd\n",
      "reload/bert/encoder/layer_7/attention/self/Reshape_1\n",
      "reload/bert/encoder/layer_7/attention/self/MatMul__845\n",
      "reload/bert/encoder/layer_7/attention/self/MatMul\n",
      "reload/bert/encoder/layer_7/attention/self/Mul\n",
      "reload/bert/encoder/layer_7/attention/self/add\n",
      "reload/bert/encoder/layer_7/attention/self/Softmax\n",
      "reload/bert/encoder/layer_7/attention/self/MatMul_1\n",
      "reload/bert/encoder/layer_7/attention/self/transpose_3\n",
      "reload/bert/encoder/layer_7/attention/self/Reshape_3\n",
      "reload/bert/encoder/layer_7/attention/output/dense/MatMul\n",
      "reload/bert/encoder/layer_7/attention/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_7/attention/output/add\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/moments/SquaredDifference__848\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/Rsqrt__851\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_7/attention/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_7/intermediate/dense/MatMul\n",
      "reload/bert/encoder/layer_7/intermediate/dense/BiasAdd\n",
      "reload/bert/encoder/layer_7/intermediate/dense/truediv\n",
      "reload/bert/encoder/layer_7/intermediate/dense/Erf\n",
      "reload/bert/encoder/layer_7/intermediate/dense/add\n",
      "reload/bert/encoder/layer_7/intermediate/dense/mul\n",
      "reload/bert/encoder/layer_7/intermediate/dense/mul_1\n",
      "reload/bert/encoder/layer_7/output/dense/MatMul\n",
      "reload/bert/encoder/layer_7/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_7/output/add\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/moments/SquaredDifference__853\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/batchnorm/Rsqrt__856\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_7/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_8/attention/self/value/MatMul\n",
      "reload/bert/encoder/layer_8/attention/self/value/BiasAdd\n",
      "reload/bert/encoder/layer_8/attention/self/Reshape_2\n",
      "reload/bert/encoder/layer_8/attention/self/transpose_2\n",
      "reload/bert/encoder/layer_8/attention/self/query/MatMul\n",
      "reload/bert/encoder/layer_8/attention/self/query/BiasAdd\n",
      "reload/bert/encoder/layer_8/attention/self/Reshape\n",
      "reload/bert/encoder/layer_8/attention/self/transpose\n",
      "reload/bert/encoder/layer_8/attention/self/key/MatMul\n",
      "reload/bert/encoder/layer_8/attention/self/key/BiasAdd\n",
      "reload/bert/encoder/layer_8/attention/self/Reshape_1\n",
      "reload/bert/encoder/layer_8/attention/self/MatMul__861\n",
      "reload/bert/encoder/layer_8/attention/self/MatMul\n",
      "reload/bert/encoder/layer_8/attention/self/Mul\n",
      "reload/bert/encoder/layer_8/attention/self/add\n",
      "reload/bert/encoder/layer_8/attention/self/Softmax\n",
      "reload/bert/encoder/layer_8/attention/self/MatMul_1\n",
      "reload/bert/encoder/layer_8/attention/self/transpose_3\n",
      "reload/bert/encoder/layer_8/attention/self/Reshape_3\n",
      "reload/bert/encoder/layer_8/attention/output/dense/MatMul\n",
      "reload/bert/encoder/layer_8/attention/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_8/attention/output/add\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/moments/SquaredDifference__864\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/Rsqrt__867\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_8/attention/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_8/intermediate/dense/MatMul\n",
      "reload/bert/encoder/layer_8/intermediate/dense/BiasAdd\n",
      "reload/bert/encoder/layer_8/intermediate/dense/truediv\n",
      "reload/bert/encoder/layer_8/intermediate/dense/Erf\n",
      "reload/bert/encoder/layer_8/intermediate/dense/add\n",
      "reload/bert/encoder/layer_8/intermediate/dense/mul\n",
      "reload/bert/encoder/layer_8/intermediate/dense/mul_1\n",
      "reload/bert/encoder/layer_8/output/dense/MatMul\n",
      "reload/bert/encoder/layer_8/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_8/output/add\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/moments/SquaredDifference__869\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/batchnorm/Rsqrt__872\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_8/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_9/attention/self/value/MatMul\n",
      "reload/bert/encoder/layer_9/attention/self/value/BiasAdd\n",
      "reload/bert/encoder/layer_9/attention/self/Reshape_2\n",
      "reload/bert/encoder/layer_9/attention/self/transpose_2\n",
      "reload/bert/encoder/layer_9/attention/self/query/MatMul\n",
      "reload/bert/encoder/layer_9/attention/self/query/BiasAdd\n",
      "reload/bert/encoder/layer_9/attention/self/Reshape\n",
      "reload/bert/encoder/layer_9/attention/self/transpose\n",
      "reload/bert/encoder/layer_9/attention/self/key/MatMul\n",
      "reload/bert/encoder/layer_9/attention/self/key/BiasAdd\n",
      "reload/bert/encoder/layer_9/attention/self/Reshape_1\n",
      "reload/bert/encoder/layer_9/attention/self/MatMul__877\n",
      "reload/bert/encoder/layer_9/attention/self/MatMul\n",
      "reload/bert/encoder/layer_9/attention/self/Mul\n",
      "reload/bert/encoder/layer_9/attention/self/add\n",
      "reload/bert/encoder/layer_9/attention/self/Softmax\n",
      "reload/bert/encoder/layer_9/attention/self/MatMul_1\n",
      "reload/bert/encoder/layer_9/attention/self/transpose_3\n",
      "reload/bert/encoder/layer_9/attention/self/Reshape_3\n",
      "reload/bert/encoder/layer_9/attention/output/dense/MatMul\n",
      "reload/bert/encoder/layer_9/attention/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_9/attention/output/add\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/moments/SquaredDifference__880\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/Rsqrt__883\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_9/attention/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_9/intermediate/dense/MatMul\n",
      "reload/bert/encoder/layer_9/intermediate/dense/BiasAdd\n",
      "reload/bert/encoder/layer_9/intermediate/dense/truediv\n",
      "reload/bert/encoder/layer_9/intermediate/dense/Erf\n",
      "reload/bert/encoder/layer_9/intermediate/dense/add\n",
      "reload/bert/encoder/layer_9/intermediate/dense/mul\n",
      "reload/bert/encoder/layer_9/intermediate/dense/mul_1\n",
      "reload/bert/encoder/layer_9/output/dense/MatMul\n",
      "reload/bert/encoder/layer_9/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_9/output/add\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/moments/SquaredDifference__885\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/batchnorm/Rsqrt__888\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_9/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_10/attention/self/value/MatMul\n",
      "reload/bert/encoder/layer_10/attention/self/value/BiasAdd\n",
      "reload/bert/encoder/layer_10/attention/self/Reshape_2\n",
      "reload/bert/encoder/layer_10/attention/self/transpose_2\n",
      "reload/bert/encoder/layer_10/attention/self/query/MatMul\n",
      "reload/bert/encoder/layer_10/attention/self/query/BiasAdd\n",
      "reload/bert/encoder/layer_10/attention/self/Reshape\n",
      "reload/bert/encoder/layer_10/attention/self/transpose\n",
      "reload/bert/encoder/layer_10/attention/self/key/MatMul\n",
      "reload/bert/encoder/layer_10/attention/self/key/BiasAdd\n",
      "reload/bert/encoder/layer_10/attention/self/Reshape_1\n",
      "reload/bert/encoder/layer_10/attention/self/MatMul__893\n",
      "reload/bert/encoder/layer_10/attention/self/MatMul\n",
      "reload/bert/encoder/layer_10/attention/self/Mul\n",
      "reload/bert/encoder/layer_10/attention/self/add\n",
      "reload/bert/encoder/layer_10/attention/self/Softmax\n",
      "reload/bert/encoder/layer_10/attention/self/MatMul_1\n",
      "reload/bert/encoder/layer_10/attention/self/transpose_3\n",
      "reload/bert/encoder/layer_10/attention/self/Reshape_3\n",
      "reload/bert/encoder/layer_10/attention/output/dense/MatMul\n",
      "reload/bert/encoder/layer_10/attention/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_10/attention/output/add\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/moments/SquaredDifference__896\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/Rsqrt__899\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_10/attention/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_10/intermediate/dense/MatMul\n",
      "reload/bert/encoder/layer_10/intermediate/dense/BiasAdd\n",
      "reload/bert/encoder/layer_10/intermediate/dense/truediv\n",
      "reload/bert/encoder/layer_10/intermediate/dense/Erf\n",
      "reload/bert/encoder/layer_10/intermediate/dense/add\n",
      "reload/bert/encoder/layer_10/intermediate/dense/mul\n",
      "reload/bert/encoder/layer_10/intermediate/dense/mul_1\n",
      "reload/bert/encoder/layer_10/output/dense/MatMul\n",
      "reload/bert/encoder/layer_10/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_10/output/add\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/moments/SquaredDifference__901\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/batchnorm/Rsqrt__904\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_10/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_11/attention/self/value/MatMul\n",
      "reload/bert/encoder/layer_11/attention/self/value/BiasAdd\n",
      "reload/bert/encoder/layer_11/attention/self/Reshape_2\n",
      "reload/bert/encoder/layer_11/attention/self/transpose_2\n",
      "reload/bert/encoder/layer_11/attention/self/query/MatMul\n",
      "reload/bert/encoder/layer_11/attention/self/query/BiasAdd\n",
      "reload/bert/encoder/layer_11/attention/self/Reshape\n",
      "reload/bert/encoder/layer_11/attention/self/transpose\n",
      "reload/bert/encoder/layer_11/attention/self/key/MatMul\n",
      "reload/bert/encoder/layer_11/attention/self/key/BiasAdd\n",
      "reload/bert/encoder/layer_11/attention/self/Reshape_1\n",
      "reload/bert/encoder/layer_11/attention/self/MatMul__909\n",
      "reload/bert/encoder/layer_11/attention/self/MatMul\n",
      "reload/bert/encoder/layer_11/attention/self/Mul\n",
      "reload/bert/encoder/layer_11/attention/self/add\n",
      "reload/bert/encoder/layer_11/attention/self/Softmax\n",
      "reload/bert/encoder/layer_11/attention/self/MatMul_1\n",
      "reload/bert/encoder/layer_11/attention/self/transpose_3\n",
      "reload/bert/encoder/layer_11/attention/self/Reshape_3\n",
      "reload/bert/encoder/layer_11/attention/output/dense/MatMul\n",
      "reload/bert/encoder/layer_11/attention/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_11/attention/output/add\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/moments/SquaredDifference__912\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/Rsqrt__915\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_11/attention/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/layer_11/intermediate/dense/MatMul\n",
      "reload/bert/encoder/layer_11/intermediate/dense/BiasAdd\n",
      "reload/bert/encoder/layer_11/intermediate/dense/truediv\n",
      "reload/bert/encoder/layer_11/intermediate/dense/Erf\n",
      "reload/bert/encoder/layer_11/intermediate/dense/add\n",
      "reload/bert/encoder/layer_11/intermediate/dense/mul\n",
      "reload/bert/encoder/layer_11/intermediate/dense/mul_1\n",
      "reload/bert/encoder/layer_11/output/dense/MatMul\n",
      "reload/bert/encoder/layer_11/output/dense/BiasAdd\n",
      "reload/bert/encoder/layer_11/output/add\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/moments/mean\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference/Cast_1\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference/Cast_0\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/moments/SquaredDifference__917\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/moments/variance\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/batchnorm/add/Cast_0\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/batchnorm/add\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/batchnorm/Rsqrt__920\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_2\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/batchnorm/sub\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/batchnorm/mul_1\n",
      "reload/bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1\n",
      "reload/bert/encoder/Reshape_13\n"
     ]
    }
   ],
   "source": [
    "for node in m.graph.node:\n",
    "    if any([node.name.startswith(s) for s in selected_names]):\n",
    "        print(node.name)\n",
    "        # node.attribute[-1].i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in m.graph.node:\n",
    "    if node.name.startswith(\"reload/bert/encoder/\") and \"layer_\" not in node.name:\n",
    "        # print(node.name)\n",
    "        node.attribute[-1].i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in m.graph.node:\n",
    "    if node.name.startswith(\"reload/\") and \"bert\" not in node.name:\n",
    "        # print(node.name)\n",
    "        node.attribute[-1].i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(851,\n",
       "  input: \"reload_qt/bert/encoder/layer_11/output/LayerNorm/batchnorm/add_1:0\"\n",
       "  input: \"reload_qt/bert/encoder/Reshape_13__1389:0\"\n",
       "  output: \"reload_qt/bert/encoder/Reshape_13:0\"\n",
       "  name: \"reload_qt/bert/encoder/Reshape_13\"\n",
       "  op_type: \"Reshape\"\n",
       "  attribute {\n",
       "    name: \"__ipu_number\"\n",
       "    i: 1\n",
       "    type: INT\n",
       "  })]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, n) for i, n in enumerate(m.graph.node) if n.name == \"reload_qt/bert/encoder/Reshape_13\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.graph.node[1648].attribute[-1].i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(918,\n",
       "  input: \"reload/bert/encoder/layer_0/attention/self/Mul:0\"\n",
       "  input: \"reload/bert/encoder/layer_9/attention/self/mul_1:0\"\n",
       "  output: \"reload/bert/encoder/layer_0/attention/self/add:0\"\n",
       "  name: \"reload/bert/encoder/layer_0/attention/self/add\"\n",
       "  op_type: \"Add\"\n",
       "  attribute {\n",
       "    name: \"__ipu_number\"\n",
       "    i: 0\n",
       "    type: INT\n",
       "  })]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, n) for i, n in enumerate(m.graph.node) if n.name == \"reload/bert/encoder/layer_0/attention/self/add\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.graph.node[918].attribute[-1].i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(35,\n",
       "  input: \"reload/bert/encoder/layer_7/attention/self/sub/x:0\"\n",
       "  input: \"reload/bert/encoder/layer_0/attention/self/ExpandDims:0\"\n",
       "  output: \"reload/bert/encoder/layer_9/attention/self/sub:0\"\n",
       "  name: \"reload/bert/encoder/layer_9/attention/self/sub\"\n",
       "  op_type: \"Sub\"\n",
       "  attribute {\n",
       "    name: \"__ipu_number\"\n",
       "    i: 1\n",
       "    type: INT\n",
       "  })]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, n) for i, n in enumerate(m.graph.node) if n.name == \"reload/bert/encoder/layer_9/attention/self/sub\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.graph.node[35].attribute[-1].i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(36,\n",
       "  input: \"reload/bert/encoder/layer_9/attention/self/sub:0\"\n",
       "  input: \"reload/bert/encoder/layer_1/attention/self/mul_1/y:0\"\n",
       "  output: \"reload/bert/encoder/layer_9/attention/self/mul_1:0\"\n",
       "  name: \"reload/bert/encoder/layer_9/attention/self/mul_1\"\n",
       "  op_type: \"Mul\"\n",
       "  attribute {\n",
       "    name: \"__ipu_number\"\n",
       "    i: 1\n",
       "    type: INT\n",
       "  })]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i, n) for i, n in enumerate(m.graph.node) if n.name == \"reload/bert/encoder/layer_9/attention/self/mul_1\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in m.graph.node:\n",
    "    if node.name.startswith(\"reload_qt/bert/pooler/\"):\n",
    "        node.attribute[-1].i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.graph.node[36].attribute[-1].i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.checker.check_model(m,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(m, \"qtc35-onnx-pipeline/model-on-half.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
